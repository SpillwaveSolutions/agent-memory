---
phase: 10-background-scheduler
plan: 04
type: execute
wave: 3
depends_on: ["10-02"]
files_modified:
  - proto/memory.proto
  - crates/memory-service/src/scheduler_service.rs
  - crates/memory-service/src/lib.rs
  - crates/memory-service/build.rs
  - crates/memory-daemon/src/cli.rs
  - crates/memory-daemon/src/commands.rs
autonomous: true

must_haves:
  truths:
    - "Job status queryable via gRPC GetSchedulerStatus RPC"
    - "CLI shows job status with last run and next run times"
    - "Job list shows success/failure counts"
    - "Scheduler status distinguishes running vs stopped"
  artifacts:
    - path: "proto/memory.proto"
      provides: "Scheduler status proto messages"
      contains: "GetSchedulerStatus"
    - path: "crates/memory-service/src/scheduler_service.rs"
      provides: "gRPC scheduler status implementation"
      exports: ["SchedulerServiceImpl"]
    - path: "crates/memory-daemon/src/cli.rs"
      provides: "CLI scheduler commands"
      contains: "SchedulerCommands"
  key_links:
    - from: "crates/memory-service/src/scheduler_service.rs"
      to: "memory_scheduler::JobRegistry"
      via: "reads job status from registry"
      pattern: "registry.get_all_status"
    - from: "crates/memory-daemon/src/commands.rs"
      to: "crates/memory-service/src/scheduler_service.rs"
      via: "CLI calls gRPC to get status"
      pattern: "GetSchedulerStatus"
---

<objective>
Add job observability via gRPC status RPC and CLI commands.

Purpose: Enable monitoring of scheduled jobs through both gRPC API and CLI.
Output: GetSchedulerStatus RPC, scheduler CLI subcommand.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/10-background-scheduler/10-RESEARCH.md
@.planning/phases/10-background-scheduler/10-02-SUMMARY.md
@proto/memory.proto
@crates/memory-service/src/lib.rs
@crates/memory-daemon/src/cli.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add scheduler proto messages and RPC</name>
  <files>
    proto/memory.proto
  </files>
  <action>
Add scheduler status messages to proto file:

1. Add to `proto/memory.proto` after existing RPCs in MemoryService:

```protobuf
    // Scheduler RPCs (SCHED-05)

    // Get scheduler and job status
    rpc GetSchedulerStatus(GetSchedulerStatusRequest) returns (GetSchedulerStatusResponse);

    // Pause a scheduled job
    rpc PauseJob(PauseJobRequest) returns (PauseJobResponse);

    // Resume a paused job
    rpc ResumeJob(ResumeJobRequest) returns (ResumeJobResponse);
```

2. Add message definitions at end of proto file:

```protobuf
// ===== Scheduler Messages (SCHED-05) =====

// Result of a job execution
enum JobResultStatus {
    JOB_RESULT_STATUS_UNSPECIFIED = 0;
    JOB_RESULT_STATUS_SUCCESS = 1;
    JOB_RESULT_STATUS_FAILED = 2;
    JOB_RESULT_STATUS_SKIPPED = 3;
}

// Status of a scheduled job
message JobStatusProto {
    // Job name
    string job_name = 1;
    // Cron expression
    string cron_expr = 2;
    // Last execution time (ms since epoch, 0 if never run)
    int64 last_run_ms = 3;
    // Last execution duration (ms)
    int64 last_duration_ms = 4;
    // Last execution result
    JobResultStatus last_result = 5;
    // Last error message (if failed)
    optional string last_error = 6;
    // Next scheduled run (ms since epoch)
    int64 next_run_ms = 7;
    // Total successful runs
    uint64 run_count = 8;
    // Total failed runs
    uint64 error_count = 9;
    // Currently executing
    bool is_running = 10;
    // Paused by user
    bool is_paused = 11;
}

// Request for scheduler status
message GetSchedulerStatusRequest {}

// Response with scheduler status
message GetSchedulerStatusResponse {
    // Whether scheduler is running
    bool scheduler_running = 1;
    // All registered jobs
    repeated JobStatusProto jobs = 2;
}

// Request to pause a job
message PauseJobRequest {
    string job_name = 1;
}

// Response from pause
message PauseJobResponse {
    bool success = 1;
    optional string error = 2;
}

// Request to resume a job
message ResumeJobRequest {
    string job_name = 1;
}

// Response from resume
message ResumeJobResponse {
    bool success = 1;
    optional string error = 2;
}
```

Note: Use JobStatusProto (not JobStatus) to avoid conflict with Rust type.
  </action>
  <verify>
    cd /Users/richardhightower/clients/spillwave/src/agent-memory && cargo build -p memory-service
  </verify>
  <done>
    Proto compiles. GetSchedulerStatus and pause/resume RPCs defined.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement gRPC scheduler service</name>
  <files>
    crates/memory-service/Cargo.toml
    crates/memory-service/src/scheduler_service.rs
    crates/memory-service/src/lib.rs
    crates/memory-service/src/server.rs
  </files>
  <action>
Implement scheduler status gRPC handlers:

1. Update `crates/memory-service/Cargo.toml`:
   - Add dependency: memory-scheduler = { workspace = true }

2. Create `crates/memory-service/src/scheduler_service.rs`:

```rust
//! gRPC scheduler status service implementation.
//!
//! Per SCHED-05: Job status observable via gRPC.

use std::sync::Arc;
use tonic::{Request, Response, Status};

use memory_scheduler::{JobRegistry, JobResult, SchedulerService};

use crate::pb::{
    GetSchedulerStatusRequest, GetSchedulerStatusResponse,
    PauseJobRequest, PauseJobResponse,
    ResumeJobRequest, ResumeJobResponse,
    JobStatusProto, JobResultStatus,
};

/// Convert JobResult to proto enum
fn job_result_to_proto(result: &JobResult) -> (JobResultStatus, Option<String>) {
    match result {
        JobResult::Success => (JobResultStatus::Success, None),
        JobResult::Failed(msg) => (JobResultStatus::Failed, Some(msg.clone())),
        JobResult::Skipped(msg) => (JobResultStatus::Skipped, Some(msg.clone())),
    }
}

/// gRPC service for scheduler status and control
pub struct SchedulerGrpcService {
    scheduler: Arc<SchedulerService>,
}

impl SchedulerGrpcService {
    pub fn new(scheduler: Arc<SchedulerService>) -> Self {
        Self { scheduler }
    }

    pub async fn get_scheduler_status(
        &self,
        _request: Request<GetSchedulerStatusRequest>,
    ) -> Result<Response<GetSchedulerStatusResponse>, Status> {
        let registry = self.scheduler.registry();
        let statuses = registry.get_all_status();

        let jobs: Vec<JobStatusProto> = statuses
            .into_iter()
            .map(|s| {
                let (result_status, error) = s.last_result
                    .as_ref()
                    .map(job_result_to_proto)
                    .unwrap_or((JobResultStatus::Unspecified, None));

                JobStatusProto {
                    job_name: s.job_name,
                    cron_expr: s.cron_expr,
                    last_run_ms: s.last_run.map(|t| t.timestamp_millis()).unwrap_or(0),
                    last_duration_ms: s.last_duration_ms.unwrap_or(0) as i64,
                    last_result: result_status.into(),
                    last_error: error,
                    next_run_ms: s.next_run.map(|t| t.timestamp_millis()).unwrap_or(0),
                    run_count: s.run_count,
                    error_count: s.error_count,
                    is_running: s.is_running,
                    is_paused: s.is_paused,
                }
            })
            .collect();

        Ok(Response::new(GetSchedulerStatusResponse {
            scheduler_running: self.scheduler.is_running(),
            jobs,
        }))
    }

    pub async fn pause_job(
        &self,
        request: Request<PauseJobRequest>,
    ) -> Result<Response<PauseJobResponse>, Status> {
        let job_name = &request.get_ref().job_name;

        match self.scheduler.pause_job(job_name).await {
            Ok(()) => Ok(Response::new(PauseJobResponse {
                success: true,
                error: None,
            })),
            Err(e) => Ok(Response::new(PauseJobResponse {
                success: false,
                error: Some(e.to_string()),
            })),
        }
    }

    pub async fn resume_job(
        &self,
        request: Request<ResumeJobRequest>,
    ) -> Result<Response<ResumeJobResponse>, Status> {
        let job_name = &request.get_ref().job_name;

        match self.scheduler.resume_job(job_name).await {
            Ok(()) => Ok(Response::new(ResumeJobResponse {
                success: true,
                error: None,
            })),
            Err(e) => Ok(Response::new(ResumeJobResponse {
                success: false,
                error: Some(e.to_string()),
            })),
        }
    }
}
```

3. Update `crates/memory-service/src/lib.rs`:
   - Add module: pub mod scheduler_service;
   - Export: SchedulerGrpcService

4. Update `crates/memory-service/src/server.rs`:
   - Add scheduler parameter to run_server_with_shutdown
   - Register scheduler service methods with gRPC server
   - Note: This requires updating the MemoryService trait implementation
     to include scheduler RPCs, OR creating a separate service.

   For simplicity, add scheduler methods to MemoryServiceImpl:
   - Add scheduler: Option<Arc<SchedulerService>> field
   - Add set_scheduler method
   - Implement scheduler RPC handlers that delegate to SchedulerGrpcService

5. Add tests for scheduler status RPC
  </action>
  <verify>
    cd /Users/richardhightower/clients/spillwave/src/agent-memory && cargo test -p memory-service scheduler
  </verify>
  <done>
    GetSchedulerStatus RPC returns job list. Pause/Resume RPCs work. Tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add CLI scheduler commands</name>
  <files>
    crates/memory-daemon/src/cli.rs
    crates/memory-daemon/src/commands.rs
  </files>
  <action>
Add scheduler subcommand to CLI:

1. Update `crates/memory-daemon/src/cli.rs`:

Add SchedulerCommands enum:
```rust
#[derive(Subcommand)]
pub enum SchedulerCommands {
    /// Show scheduler and job status
    Status,
    /// Pause a scheduled job
    Pause {
        /// Job name to pause
        job_name: String,
    },
    /// Resume a paused job
    Resume {
        /// Job name to resume
        job_name: String,
    },
}
```

Add to Commands enum:
```rust
    /// Scheduler management commands
    Scheduler {
        /// gRPC endpoint (default: http://127.0.0.1:50051)
        #[arg(long, default_value = "http://127.0.0.1:50051")]
        endpoint: String,
        #[command(subcommand)]
        command: SchedulerCommands,
    },
```

2. Update `crates/memory-daemon/src/commands.rs`:

Add handle_scheduler function:
```rust
pub async fn handle_scheduler(endpoint: &str, command: SchedulerCommands) -> Result<()> {
    use memory_service::pb::memory_service_client::MemoryServiceClient;

    let mut client = MemoryServiceClient::connect(endpoint.to_string()).await?;

    match command {
        SchedulerCommands::Status => {
            let response = client
                .get_scheduler_status(GetSchedulerStatusRequest {})
                .await?
                .into_inner();

            println!("Scheduler: {}", if response.scheduler_running { "RUNNING" } else { "STOPPED" });
            println!();

            if response.jobs.is_empty() {
                println!("No jobs registered.");
            } else {
                println!("{:<20} {:<12} {:<20} {:<20} {:<10} {:<10}",
                    "JOB", "STATUS", "LAST RUN", "NEXT RUN", "RUNS", "ERRORS");
                println!("{}", "-".repeat(92));

                for job in response.jobs {
                    let status = if job.is_paused {
                        "PAUSED"
                    } else if job.is_running {
                        "RUNNING"
                    } else {
                        "IDLE"
                    };

                    let last_run = if job.last_run_ms > 0 {
                        format_timestamp(job.last_run_ms)
                    } else {
                        "Never".to_string()
                    };

                    let next_run = if job.next_run_ms > 0 && !job.is_paused {
                        format_timestamp(job.next_run_ms)
                    } else {
                        "-".to_string()
                    };

                    println!("{:<20} {:<12} {:<20} {:<20} {:<10} {:<10}",
                        job.job_name, status, last_run, next_run,
                        job.run_count, job.error_count);
                }
            }
        }
        SchedulerCommands::Pause { job_name } => {
            let response = client
                .pause_job(PauseJobRequest { job_name: job_name.clone() })
                .await?
                .into_inner();

            if response.success {
                println!("Job '{}' paused.", job_name);
            } else {
                println!("Failed to pause '{}': {}", job_name, response.error.unwrap_or_default());
            }
        }
        SchedulerCommands::Resume { job_name } => {
            let response = client
                .resume_job(ResumeJobRequest { job_name: job_name.clone() })
                .await?
                .into_inner();

            if response.success {
                println!("Job '{}' resumed.", job_name);
            } else {
                println!("Failed to resume '{}': {}", job_name, response.error.unwrap_or_default());
            }
        }
    }

    Ok(())
}

fn format_timestamp(ms: i64) -> String {
    use chrono::{DateTime, Utc, Local};
    let dt = DateTime::<Utc>::from_timestamp_millis(ms)
        .map(|t| t.with_timezone(&Local));
    dt.map(|t| t.format("%Y-%m-%d %H:%M").to_string())
        .unwrap_or_else(|| "Invalid".to_string())
}
```

3. Update main.rs to handle Scheduler command:
```rust
Commands::Scheduler { endpoint, command } => {
    handle_scheduler(&endpoint, command).await?;
}
```

4. Update lib.rs to export new types
  </action>
  <verify>
    cd /Users/richardhightower/clients/spillwave/src/agent-memory && cargo build -p memory-daemon && ./target/debug/memory-daemon scheduler --help
  </verify>
  <done>
    CLI scheduler subcommand works. status/pause/resume commands implemented.
  </done>
</task>

</tasks>

<verification>
```bash
cd /Users/richardhightower/clients/spillwave/src/agent-memory

# Proto compiles
cargo build -p memory-service

# Daemon builds with scheduler CLI
cargo build -p memory-daemon

# CLI help shows scheduler commands
./target/debug/memory-daemon scheduler --help
./target/debug/memory-daemon scheduler status --help
./target/debug/memory-daemon scheduler pause --help
./target/debug/memory-daemon scheduler resume --help

# All tests pass
cargo test -p memory-service -p memory-daemon

# Clippy clean
cargo clippy -p memory-service -p memory-daemon -- -D warnings
```
</verification>

<success_criteria>
- [ ] GetSchedulerStatus RPC defined in proto
- [ ] PauseJob/ResumeJob RPCs defined in proto
- [ ] SchedulerGrpcService implements all scheduler RPCs
- [ ] Job status includes all fields (name, cron, last_run, next_run, counts)
- [ ] CLI scheduler status shows formatted job table
- [ ] CLI scheduler pause/resume work
- [ ] Timestamps formatted in local time for CLI
- [ ] All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/10-background-scheduler/10-04-SUMMARY.md`
</output>
