---
phase: 02-toc-building
plan: 03
type: execute
wave: 2
depends_on: ["02-01", "02-02"]
files_modified:
  - crates/memory-toc/src/builder.rs
  - crates/memory-toc/src/node_id.rs
  - crates/memory-toc/src/rollup.rs
  - crates/memory-toc/src/lib.rs
  - crates/memory-storage/src/db.rs
  - crates/memory-storage/src/column_families.rs
autonomous: true

must_haves:
  truths:
    - "TOC nodes exist at all levels (Year, Month, Week, Day, Segment)"
    - "Node IDs encode level and time period hierarchically"
    - "Segments summarized and stored as TOC nodes"
    - "Rollup jobs aggregate child nodes into parent summaries"
    - "Checkpoints enable crash recovery for rollup jobs"
    - "Versioned nodes append new version, don't mutate (TOC-06)"
  artifacts:
    - path: "crates/memory-toc/src/builder.rs"
      provides: "TOC hierarchy builder"
      exports: ["TocBuilder"]
    - path: "crates/memory-toc/src/node_id.rs"
      provides: "Node ID generation and parsing"
      exports: ["NodeId", "generate_node_id"]
    - path: "crates/memory-toc/src/rollup.rs"
      provides: "Rollup job implementation"
      exports: ["RollupJob", "RollupCheckpoint"]
  key_links:
    - from: "crates/memory-toc/src/builder.rs"
      to: "crates/memory-storage/src/db.rs"
      via: "Storage for TOC nodes"
      pattern: "Storage"
    - from: "crates/memory-toc/src/rollup.rs"
      to: "crates/memory-toc/src/summarizer/mod.rs"
      via: "Summarizer for rollups"
      pattern: "summarize_children"
---

<objective>
Implement TOC hierarchy builder with rollup jobs and checkpointing.

Purpose: Build the complete TOC hierarchy from segments to year, with crash-recoverable rollup jobs.
Output: TocBuilder that creates segment nodes and rollup jobs that aggregate into parent nodes.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-toc-building/02-RESEARCH.md
@.planning/phases/02-toc-building/02-01-SUMMARY.md
@.planning/phases/02-toc-building/02-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add TOC storage methods to Storage</name>
  <files>
    - crates/memory-storage/src/db.rs
    - crates/memory-storage/src/column_families.rs
  </files>
  <action>
Add methods for storing and retrieving TOC nodes with versioning.

**Update crates/memory-storage/src/db.rs to add TOC methods:**

Add these methods to the Storage impl block:

```rust
use crate::column_families::{CF_TOC_NODES, CF_TOC_LATEST};

impl Storage {
    // ... existing methods ...

    /// Store a TOC node with versioning (TOC-06).
    ///
    /// Appends a new version rather than mutating.
    /// Updates toc_latest to point to new version.
    pub fn put_toc_node(&self, node: &memory_types::TocNode) -> Result<(), StorageError> {
        let nodes_cf = self.db.cf_handle(CF_TOC_NODES)
            .ok_or_else(|| StorageError::ColumnFamilyNotFound(CF_TOC_NODES.to_string()))?;
        let latest_cf = self.db.cf_handle(CF_TOC_LATEST)
            .ok_or_else(|| StorageError::ColumnFamilyNotFound(CF_TOC_LATEST.to_string()))?;

        // Get current version
        let latest_key = format!("latest:{}", node.node_id);
        let current_version = self.db.get_cf(&latest_cf, &latest_key)?
            .map(|b| {
                if b.len() >= 4 {
                    u32::from_be_bytes([b[0], b[1], b[2], b[3]])
                } else {
                    0
                }
            })
            .unwrap_or(0);

        let new_version = current_version + 1;
        let versioned_key = format!("toc:{}:v{:06}", node.node_id, new_version);

        // Update node version
        let mut versioned_node = node.clone();
        versioned_node.version = new_version;

        let node_bytes = versioned_node.to_bytes()
            .map_err(|e| StorageError::SerializationError(e.to_string()))?;

        // Atomic write: node + latest pointer
        let mut batch = rocksdb::WriteBatch::default();
        batch.put_cf(&nodes_cf, versioned_key.as_bytes(), &node_bytes);
        batch.put_cf(&latest_cf, latest_key.as_bytes(), &new_version.to_be_bytes());

        self.db.write(batch)?;

        debug!(node_id = %node.node_id, version = new_version, "Stored TOC node");
        Ok(())
    }

    /// Get the latest version of a TOC node.
    pub fn get_toc_node(&self, node_id: &str) -> Result<Option<memory_types::TocNode>, StorageError> {
        let nodes_cf = self.db.cf_handle(CF_TOC_NODES)
            .ok_or_else(|| StorageError::ColumnFamilyNotFound(CF_TOC_NODES.to_string()))?;
        let latest_cf = self.db.cf_handle(CF_TOC_LATEST)
            .ok_or_else(|| StorageError::ColumnFamilyNotFound(CF_TOC_LATEST.to_string()))?;

        // Get latest version number
        let latest_key = format!("latest:{}", node_id);
        let version = match self.db.get_cf(&latest_cf, &latest_key)? {
            Some(b) if b.len() >= 4 => u32::from_be_bytes([b[0], b[1], b[2], b[3]]),
            _ => return Ok(None),
        };

        // Get versioned node
        let versioned_key = format!("toc:{}:v{:06}", node_id, version);
        match self.db.get_cf(&nodes_cf, versioned_key.as_bytes())? {
            Some(bytes) => {
                let node = memory_types::TocNode::from_bytes(&bytes)
                    .map_err(|e| StorageError::SerializationError(e.to_string()))?;
                Ok(Some(node))
            }
            None => Ok(None),
        }
    }

    /// Get TOC nodes by level, optionally filtered by time range.
    pub fn get_toc_nodes_by_level(
        &self,
        level: memory_types::TocLevel,
        start_time: Option<chrono::DateTime<chrono::Utc>>,
        end_time: Option<chrono::DateTime<chrono::Utc>>,
    ) -> Result<Vec<memory_types::TocNode>, StorageError> {
        let nodes_cf = self.db.cf_handle(CF_TOC_NODES)
            .ok_or_else(|| StorageError::ColumnFamilyNotFound(CF_TOC_NODES.to_string()))?;
        let latest_cf = self.db.cf_handle(CF_TOC_LATEST)
            .ok_or_else(|| StorageError::ColumnFamilyNotFound(CF_TOC_LATEST.to_string()))?;

        let level_prefix = format!("toc:{}:", level);
        let mut nodes = Vec::new();

        // Iterate through latest pointers to find all nodes of this level
        let iter = self.db.iterator_cf(
            &latest_cf,
            rocksdb::IteratorMode::From(format!("latest:toc:{}:", level).as_bytes(), rocksdb::Direction::Forward),
        );

        for item in iter {
            let (key, value) = item?;
            let key_str = String::from_utf8_lossy(&key);

            // Stop if we've passed this level's prefix
            if !key_str.starts_with(&format!("latest:toc:{}:", level)) {
                break;
            }

            // Get the node_id from key
            let node_id = key_str.trim_start_matches("latest:");
            if value.len() >= 4 {
                let version = u32::from_be_bytes([value[0], value[1], value[2], value[3]]);
                let versioned_key = format!("{}:v{:06}", node_id, version);

                if let Some(bytes) = self.db.get_cf(&nodes_cf, versioned_key.as_bytes())? {
                    let node = memory_types::TocNode::from_bytes(&bytes)
                        .map_err(|e| StorageError::SerializationError(e.to_string()))?;

                    // Filter by time range if specified
                    let include = match (start_time, end_time) {
                        (Some(start), Some(end)) => node.end_time >= start && node.start_time <= end,
                        (Some(start), None) => node.end_time >= start,
                        (None, Some(end)) => node.start_time <= end,
                        (None, None) => true,
                    };

                    if include {
                        nodes.push(node);
                    }
                }
            }
        }

        // Sort by start_time
        nodes.sort_by(|a, b| a.start_time.cmp(&b.start_time));

        Ok(nodes)
    }

    /// Get child nodes of a parent node.
    pub fn get_child_nodes(&self, parent_node_id: &str) -> Result<Vec<memory_types::TocNode>, StorageError> {
        let parent = self.get_toc_node(parent_node_id)?;
        match parent {
            Some(node) => {
                let mut children = Vec::new();
                for child_id in &node.child_node_ids {
                    if let Some(child) = self.get_toc_node(child_id)? {
                        children.push(child);
                    }
                }
                children.sort_by(|a, b| a.start_time.cmp(&b.start_time));
                Ok(children)
            }
            None => Ok(Vec::new()),
        }
    }
}
```
  </action>
  <verify>
`cargo build -p memory-storage` compiles with TOC methods.
  </verify>
  <done>
Storage has methods for versioned TOC node storage and retrieval.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement Node ID generation</name>
  <files>
    - crates/memory-toc/src/node_id.rs
    - crates/memory-toc/src/lib.rs
  </files>
  <action>
Create node ID generation that encodes level and time period.

**Create crates/memory-toc/src/node_id.rs:**
```rust
//! TOC node ID generation and parsing.
//!
//! Node IDs encode the level and time period for hierarchical organization.
//! Format: "toc:{level}:{time_identifier}"

use chrono::{DateTime, Datelike, IsoWeek, Utc, Weekday};
use memory_types::TocLevel;

/// Generate a node ID for the given level and time.
///
/// Examples:
/// - Year: "toc:year:2024"
/// - Month: "toc:month:2024:01"
/// - Week: "toc:week:2024:W03"
/// - Day: "toc:day:2024-01-15"
/// - Segment: "toc:segment:2024-01-15:01HN4QXKN6..."
pub fn generate_node_id(level: TocLevel, time: DateTime<Utc>) -> String {
    match level {
        TocLevel::Year => format!("toc:year:{}", time.year()),
        TocLevel::Month => format!("toc:month:{}:{:02}", time.year(), time.month()),
        TocLevel::Week => {
            let iso_week = time.iso_week();
            format!("toc:week:{}:W{:02}", iso_week.year(), iso_week.week())
        }
        TocLevel::Day => format!("toc:day:{}", time.format("%Y-%m-%d")),
        TocLevel::Segment => format!(
            "toc:segment:{}:{}",
            time.format("%Y-%m-%d"),
            ulid::Ulid::new()
        ),
    }
}

/// Generate a node ID for a segment with a specific ULID.
pub fn generate_segment_node_id(time: DateTime<Utc>, segment_ulid: &str) -> String {
    format!("toc:segment:{}:{}", time.format("%Y-%m-%d"), segment_ulid)
}

/// Get the parent node ID for a given node ID.
///
/// Returns None for year-level nodes (no parent).
pub fn get_parent_node_id(node_id: &str) -> Option<String> {
    let parts: Vec<&str> = node_id.split(':').collect();
    if parts.len() < 3 || parts[0] != "toc" {
        return None;
    }

    match parts[1] {
        "segment" => {
            // toc:segment:2024-01-15:ulid -> toc:day:2024-01-15
            if parts.len() >= 3 {
                Some(format!("toc:day:{}", parts[2]))
            } else {
                None
            }
        }
        "day" => {
            // toc:day:2024-01-15 -> toc:week:2024:W03
            if parts.len() >= 3 {
                if let Ok(date) = chrono::NaiveDate::parse_from_str(parts[2], "%Y-%m-%d") {
                    let iso_week = date.iso_week();
                    return Some(format!("toc:week:{}:W{:02}", iso_week.year(), iso_week.week()));
                }
            }
            None
        }
        "week" => {
            // toc:week:2024:W03 -> toc:month:2024:01
            // Need to find which month the week belongs to (use middle of week)
            if parts.len() >= 4 {
                if let (Ok(year), Ok(week)) = (
                    parts[2].parse::<i32>(),
                    parts[3].trim_start_matches('W').parse::<u32>(),
                ) {
                    // Get the Thursday of the week to determine the month
                    if let Some(date) = chrono::NaiveDate::from_isoywd_opt(year, week, Weekday::Thu) {
                        return Some(format!("toc:month:{}:{:02}", date.year(), date.month()));
                    }
                }
            }
            None
        }
        "month" => {
            // toc:month:2024:01 -> toc:year:2024
            if parts.len() >= 3 {
                Some(format!("toc:year:{}", parts[2]))
            } else {
                None
            }
        }
        "year" => None, // Year has no parent
        _ => None,
    }
}

/// Parse level from node ID.
pub fn parse_level(node_id: &str) -> Option<TocLevel> {
    let parts: Vec<&str> = node_id.split(':').collect();
    if parts.len() < 2 || parts[0] != "toc" {
        return None;
    }

    match parts[1] {
        "year" => Some(TocLevel::Year),
        "month" => Some(TocLevel::Month),
        "week" => Some(TocLevel::Week),
        "day" => Some(TocLevel::Day),
        "segment" => Some(TocLevel::Segment),
        _ => None,
    }
}

/// Generate human-readable title for a node.
pub fn generate_title(level: TocLevel, time: DateTime<Utc>) -> String {
    match level {
        TocLevel::Year => format!("{}", time.year()),
        TocLevel::Month => time.format("%B %Y").to_string(),
        TocLevel::Week => {
            let iso_week = time.iso_week();
            format!("Week {} of {}", iso_week.week(), iso_week.year())
        }
        TocLevel::Day => time.format("%A, %B %d, %Y").to_string(),
        TocLevel::Segment => time.format("%B %d, %Y at %H:%M").to_string(),
    }
}

/// Get the time boundaries for a level at a given time.
pub fn get_time_boundaries(level: TocLevel, time: DateTime<Utc>) -> (DateTime<Utc>, DateTime<Utc>) {
    use chrono::{Duration, NaiveTime, TimeZone};

    match level {
        TocLevel::Year => {
            let start = Utc.with_ymd_and_hms(time.year(), 1, 1, 0, 0, 0).unwrap();
            let end = Utc.with_ymd_and_hms(time.year() + 1, 1, 1, 0, 0, 0).unwrap() - Duration::milliseconds(1);
            (start, end)
        }
        TocLevel::Month => {
            let start = Utc.with_ymd_and_hms(time.year(), time.month(), 1, 0, 0, 0).unwrap();
            let next_month = if time.month() == 12 {
                Utc.with_ymd_and_hms(time.year() + 1, 1, 1, 0, 0, 0).unwrap()
            } else {
                Utc.with_ymd_and_hms(time.year(), time.month() + 1, 1, 0, 0, 0).unwrap()
            };
            let end = next_month - Duration::milliseconds(1);
            (start, end)
        }
        TocLevel::Week => {
            let iso_week = time.iso_week();
            let monday = chrono::NaiveDate::from_isoywd_opt(iso_week.year(), iso_week.week(), Weekday::Mon).unwrap();
            let start = Utc.from_utc_datetime(&monday.and_time(NaiveTime::MIN));
            let end = start + Duration::days(7) - Duration::milliseconds(1);
            (start, end)
        }
        TocLevel::Day => {
            let date = time.date_naive();
            let start = Utc.from_utc_datetime(&date.and_time(NaiveTime::MIN));
            let end = start + Duration::days(1) - Duration::milliseconds(1);
            (start, end)
        }
        TocLevel::Segment => {
            // Segments have explicit boundaries, not calculated
            (time, time)
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use chrono::TimeZone;

    #[test]
    fn test_generate_node_id_year() {
        let time = Utc.with_ymd_and_hms(2024, 6, 15, 12, 0, 0).unwrap();
        let id = generate_node_id(TocLevel::Year, time);
        assert_eq!(id, "toc:year:2024");
    }

    #[test]
    fn test_generate_node_id_month() {
        let time = Utc.with_ymd_and_hms(2024, 1, 15, 12, 0, 0).unwrap();
        let id = generate_node_id(TocLevel::Month, time);
        assert_eq!(id, "toc:month:2024:01");
    }

    #[test]
    fn test_generate_node_id_week() {
        let time = Utc.with_ymd_and_hms(2024, 1, 18, 12, 0, 0).unwrap();
        let id = generate_node_id(TocLevel::Week, time);
        assert!(id.starts_with("toc:week:2024:W"));
    }

    #[test]
    fn test_generate_node_id_day() {
        let time = Utc.with_ymd_and_hms(2024, 1, 15, 12, 0, 0).unwrap();
        let id = generate_node_id(TocLevel::Day, time);
        assert_eq!(id, "toc:day:2024-01-15");
    }

    #[test]
    fn test_generate_node_id_segment() {
        let time = Utc.with_ymd_and_hms(2024, 1, 15, 12, 0, 0).unwrap();
        let id = generate_node_id(TocLevel::Segment, time);
        assert!(id.starts_with("toc:segment:2024-01-15:"));
    }

    #[test]
    fn test_get_parent_node_id() {
        assert_eq!(
            get_parent_node_id("toc:day:2024-01-15"),
            Some("toc:week:2024:W03".to_string())
        );
        assert_eq!(
            get_parent_node_id("toc:month:2024:01"),
            Some("toc:year:2024".to_string())
        );
        assert_eq!(get_parent_node_id("toc:year:2024"), None);
    }

    #[test]
    fn test_parse_level() {
        assert_eq!(parse_level("toc:year:2024"), Some(TocLevel::Year));
        assert_eq!(parse_level("toc:month:2024:01"), Some(TocLevel::Month));
        assert_eq!(parse_level("toc:day:2024-01-15"), Some(TocLevel::Day));
        assert_eq!(parse_level("invalid"), None);
    }

    #[test]
    fn test_generate_title() {
        let time = Utc.with_ymd_and_hms(2024, 1, 15, 12, 0, 0).unwrap();
        assert_eq!(generate_title(TocLevel::Year, time), "2024");
        assert_eq!(generate_title(TocLevel::Month, time), "January 2024");
    }

    #[test]
    fn test_get_time_boundaries_day() {
        let time = Utc.with_ymd_and_hms(2024, 1, 15, 12, 30, 0).unwrap();
        let (start, end) = get_time_boundaries(TocLevel::Day, time);

        assert_eq!(start, Utc.with_ymd_and_hms(2024, 1, 15, 0, 0, 0).unwrap());
        assert!(end > start);
        assert!(end < Utc.with_ymd_and_hms(2024, 1, 16, 0, 0, 0).unwrap());
    }
}
```

**Update crates/memory-toc/src/lib.rs:**
```rust
//! TOC building library for agent-memory.
//!
//! Provides:
//! - Event segmentation (TOC-03, TOC-04)
//! - Summarization trait (SUMM-01, SUMM-02, SUMM-04)
//! - TOC hierarchy building (TOC-01, TOC-02, TOC-05)
//! - Node ID generation

pub mod builder;
pub mod config;
pub mod node_id;
pub mod rollup;
pub mod segmenter;
pub mod summarizer;

pub use builder::TocBuilder;
pub use config::{SegmentationConfig, TocConfig};
pub use node_id::{generate_node_id, generate_title, get_parent_node_id, parse_level};
pub use rollup::{RollupCheckpoint, RollupJob};
pub use segmenter::SegmentBuilder;
pub use summarizer::{ApiSummarizer, ApiSummarizerConfig, MockSummarizer, Summary, Summarizer, SummarizerError};
```
  </action>
  <verify>
`cargo build -p memory-toc` compiles with node_id module.
`cargo test -p memory-toc -- --test node_id` passes.
  </verify>
  <done>
Node ID generation encodes level and time period hierarchically.
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement TocBuilder for segment processing</name>
  <files>
    - crates/memory-toc/src/builder.rs
  </files>
  <action>
Create the TocBuilder that processes segments into TOC nodes.

**Create crates/memory-toc/src/builder.rs:**
```rust
//! TOC hierarchy builder.
//!
//! Builds TOC nodes from segments and ensures parent nodes exist.

use std::sync::Arc;
use chrono::{DateTime, Utc};
use tracing::{debug, info};

use memory_storage::Storage;
use memory_types::{Segment, TocBullet, TocLevel, TocNode};

use crate::node_id::{generate_node_id, generate_title, get_parent_node_id, get_time_boundaries};
use crate::summarizer::{Summary, Summarizer, SummarizerError};

/// Error type for TOC building.
#[derive(Debug, thiserror::Error)]
pub enum BuilderError {
    #[error("Storage error: {0}")]
    Storage(#[from] memory_storage::StorageError),

    #[error("Summarization error: {0}")]
    Summarizer(#[from] SummarizerError),

    #[error("Invalid segment: {0}")]
    InvalidSegment(String),
}

/// Builder for TOC hierarchy.
///
/// Processes segments and creates TOC nodes at all levels.
pub struct TocBuilder {
    storage: Arc<Storage>,
    summarizer: Arc<dyn Summarizer>,
}

impl TocBuilder {
    /// Create a new TocBuilder.
    pub fn new(storage: Arc<Storage>, summarizer: Arc<dyn Summarizer>) -> Self {
        Self { storage, summarizer }
    }

    /// Process a segment and create/update TOC nodes.
    ///
    /// Creates:
    /// 1. Segment-level node from the segment
    /// 2. Ensures parent nodes exist up to Year level
    pub async fn process_segment(&self, segment: &Segment) -> Result<TocNode, BuilderError> {
        if segment.events.is_empty() {
            return Err(BuilderError::InvalidSegment("Segment has no events".to_string()));
        }

        info!(
            segment_id = %segment.segment_id,
            events = segment.events.len(),
            "Processing segment"
        );

        // Summarize the segment
        let all_events: Vec<_> = segment.all_events().cloned().collect();
        let summary = self.summarizer.summarize_events(&all_events).await?;

        // Create segment node
        let segment_node = self.create_segment_node(segment, summary)?;
        self.storage.put_toc_node(&segment_node)?;

        // Ensure parent nodes exist and are updated
        self.ensure_parents(&segment_node).await?;

        Ok(segment_node)
    }

    /// Create a segment-level TOC node.
    fn create_segment_node(&self, segment: &Segment, summary: Summary) -> Result<TocNode, BuilderError> {
        let node_id = format!("toc:segment:{}:{}",
            segment.start_time.format("%Y-%m-%d"),
            segment.segment_id.trim_start_matches("seg:")
        );

        let bullets: Vec<TocBullet> = summary.bullets
            .into_iter()
            .map(TocBullet::new)
            .collect();

        let mut node = TocNode::new(
            node_id,
            TocLevel::Segment,
            summary.title,
            segment.start_time,
            segment.end_time,
        );
        node.bullets = bullets;
        node.keywords = summary.keywords;

        Ok(node)
    }

    /// Ensure parent nodes exist up to Year level.
    async fn ensure_parents(&self, child_node: &TocNode) -> Result<(), BuilderError> {
        let mut current_id = child_node.node_id.clone();
        let mut child_level = child_node.level;

        while let Some(parent_level) = child_level.parent() {
            if let Some(parent_id) = get_parent_node_id(&current_id) {
                // Check if parent exists
                let parent = self.storage.get_toc_node(&parent_id)?;

                if let Some(mut parent_node) = parent {
                    // Update parent's child list if needed
                    if !parent_node.child_node_ids.contains(&current_id) {
                        parent_node.child_node_ids.push(current_id.clone());
                        self.storage.put_toc_node(&parent_node)?;
                        debug!(
                            parent = %parent_id,
                            child = %current_id,
                            "Added child to existing parent"
                        );
                    }
                } else {
                    // Create parent node with placeholder summary
                    let parent_node = self.create_parent_node(&parent_id, parent_level, child_node, &current_id)?;
                    self.storage.put_toc_node(&parent_node)?;
                    debug!(
                        parent = %parent_id,
                        level = %parent_level,
                        "Created new parent node"
                    );
                }

                current_id = parent_id;
                child_level = parent_level;
            } else {
                break;
            }
        }

        Ok(())
    }

    /// Create a parent node with placeholder summary.
    fn create_parent_node(
        &self,
        parent_id: &str,
        level: TocLevel,
        child: &TocNode,
        child_id: &str,
    ) -> Result<TocNode, BuilderError> {
        let (start_time, end_time) = get_time_boundaries(level, child.start_time);
        let title = generate_title(level, child.start_time);

        let mut node = TocNode::new(
            parent_id.to_string(),
            level,
            title,
            start_time,
            end_time,
        );
        node.child_node_ids.push(child_id.to_string());

        // Placeholder bullet - will be replaced by rollup job
        node.bullets.push(TocBullet::new("Summary pending..."));

        Ok(node)
    }

    /// Get all segment nodes for a day.
    pub fn get_segments_for_day(&self, date: DateTime<Utc>) -> Result<Vec<TocNode>, BuilderError> {
        let day_id = generate_node_id(TocLevel::Day, date);
        self.storage.get_child_nodes(&day_id).map_err(BuilderError::from)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use memory_types::{Event, EventRole, EventType};
    use tempfile::TempDir;
    use crate::summarizer::MockSummarizer;

    fn create_test_storage() -> (Arc<Storage>, TempDir) {
        let temp_dir = TempDir::new().unwrap();
        let storage = Arc::new(Storage::open(temp_dir.path()).unwrap());
        (storage, temp_dir)
    }

    fn create_test_event(text: &str, timestamp_ms: i64) -> Event {
        let ulid = ulid::Ulid::from_parts(timestamp_ms as u64, rand::random());
        Event::new(
            ulid.to_string(),
            "session-123".to_string(),
            chrono::Utc.timestamp_millis_opt(timestamp_ms).unwrap(),
            EventType::UserMessage,
            EventRole::User,
            text.to_string(),
        )
    }

    use chrono::TimeZone;

    #[tokio::test]
    async fn test_process_segment_creates_node() {
        let (storage, _temp) = create_test_storage();
        let summarizer = Arc::new(MockSummarizer::new());
        let builder = TocBuilder::new(storage.clone(), summarizer);

        let events = vec![
            create_test_event("Hello", 1706540400000), // 2024-01-29
            create_test_event("World", 1706540500000),
        ];
        let segment = Segment::new(
            "seg:test123".to_string(),
            events.clone(),
            events[0].timestamp,
            events[1].timestamp,
            100,
        );

        let node = builder.process_segment(&segment).await.unwrap();

        assert_eq!(node.level, TocLevel::Segment);
        assert!(!node.bullets.is_empty());
    }

    #[tokio::test]
    async fn test_process_segment_creates_parents() {
        let (storage, _temp) = create_test_storage();
        let summarizer = Arc::new(MockSummarizer::new());
        let builder = TocBuilder::new(storage.clone(), summarizer);

        let events = vec![create_test_event("Test", 1706540400000)];
        let segment = Segment::new(
            "seg:test456".to_string(),
            events.clone(),
            events[0].timestamp,
            events[0].timestamp,
            50,
        );

        builder.process_segment(&segment).await.unwrap();

        // Check that day node was created
        let day_node = storage.get_toc_node("toc:day:2024-01-29").unwrap();
        assert!(day_node.is_some());

        // Check that year node was created
        let year_node = storage.get_toc_node("toc:year:2024").unwrap();
        assert!(year_node.is_some());
    }
}
```
  </action>
  <verify>
`cargo build -p memory-toc` compiles with builder module.
`cargo test -p memory-toc -- --test builder` passes.
  </verify>
  <done>
TocBuilder creates segment nodes and ensures parent hierarchy exists.
  </done>
</task>

<task type="auto">
  <name>Task 4: Implement Rollup jobs with checkpointing</name>
  <files>
    - crates/memory-toc/src/rollup.rs
  </files>
  <action>
Create rollup jobs that aggregate child nodes into parent summaries.

**Create crates/memory-toc/src/rollup.rs:**
```rust
//! Rollup jobs for aggregating child TOC nodes.
//!
//! Per TOC-05: Day/Week/Month rollup jobs with checkpointing.
//! Per SUMM-04: Rollup summarizer aggregates child node summaries.

use std::sync::Arc;
use chrono::{DateTime, Duration, Utc};
use serde::{Deserialize, Serialize};
use tracing::{debug, info, warn};

use memory_storage::Storage;
use memory_types::{TocBullet, TocLevel, TocNode};

use crate::summarizer::{Summary, Summarizer, SummarizerError};

/// Checkpoint for rollup job crash recovery.
///
/// Per STOR-03 and TOC-05: Enables crash recovery.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RollupCheckpoint {
    /// Job identifier
    pub job_name: String,

    /// Level being processed
    pub level: TocLevel,

    /// Last successfully processed time period
    #[serde(with = "chrono::serde::ts_milliseconds")]
    pub last_processed_time: DateTime<Utc>,

    /// Number of nodes processed in current run
    pub processed_count: usize,

    /// When this checkpoint was created
    #[serde(with = "chrono::serde::ts_milliseconds")]
    pub created_at: DateTime<Utc>,
}

impl RollupCheckpoint {
    pub fn new(job_name: String, level: TocLevel) -> Self {
        Self {
            job_name,
            level,
            last_processed_time: DateTime::<Utc>::MIN_UTC,
            processed_count: 0,
            created_at: Utc::now(),
        }
    }

    pub fn to_bytes(&self) -> Result<Vec<u8>, serde_json::Error> {
        serde_json::to_vec(self)
    }

    pub fn from_bytes(bytes: &[u8]) -> Result<Self, serde_json::Error> {
        serde_json::from_slice(bytes)
    }
}

/// Error type for rollup operations.
#[derive(Debug, thiserror::Error)]
pub enum RollupError {
    #[error("Storage error: {0}")]
    Storage(#[from] memory_storage::StorageError),

    #[error("Summarization error: {0}")]
    Summarizer(#[from] SummarizerError),

    #[error("No child level for {0}")]
    NoChildLevel(TocLevel),

    #[error("Checkpoint error: {0}")]
    Checkpoint(String),
}

/// Rollup job for aggregating child nodes into parent summaries.
pub struct RollupJob {
    storage: Arc<Storage>,
    summarizer: Arc<dyn Summarizer>,
    level: TocLevel,
    /// Minimum age of period before rollup (avoids rolling up incomplete periods)
    min_age: Duration,
}

impl RollupJob {
    /// Create a new rollup job for the specified level.
    ///
    /// min_age: Minimum age of a period before it can be rolled up.
    /// This prevents rolling up periods that are still receiving events.
    pub fn new(
        storage: Arc<Storage>,
        summarizer: Arc<dyn Summarizer>,
        level: TocLevel,
        min_age: Duration,
    ) -> Self {
        Self {
            storage,
            summarizer,
            level,
            min_age,
        }
    }

    /// Create rollup jobs for all levels.
    pub fn create_all(
        storage: Arc<Storage>,
        summarizer: Arc<dyn Summarizer>,
    ) -> Vec<Self> {
        vec![
            Self::new(storage.clone(), summarizer.clone(), TocLevel::Day, Duration::hours(1)),
            Self::new(storage.clone(), summarizer.clone(), TocLevel::Week, Duration::hours(24)),
            Self::new(storage.clone(), summarizer.clone(), TocLevel::Month, Duration::hours(24)),
            Self::new(storage.clone(), summarizer.clone(), TocLevel::Year, Duration::days(7)),
        ]
    }

    /// Run the rollup job.
    ///
    /// Processes nodes that need rollup since the last checkpoint.
    pub async fn run(&self) -> Result<usize, RollupError> {
        let job_name = format!("rollup_{}", self.level);
        info!(job = %job_name, level = %self.level, "Starting rollup job");

        // Load checkpoint
        let checkpoint = self.load_checkpoint(&job_name)?;
        let start_time = checkpoint.map(|c| c.last_processed_time).unwrap_or(DateTime::<Utc>::MIN_UTC);

        // Get nodes at this level that need rollup
        let cutoff_time = Utc::now() - self.min_age;
        let nodes = self.storage.get_toc_nodes_by_level(
            self.level,
            Some(start_time),
            Some(cutoff_time),
        )?;

        let mut processed = 0;

        for node in nodes {
            // Skip if period is too recent
            if node.end_time > cutoff_time {
                debug!(
                    node_id = %node.node_id,
                    "Skipping node - period not yet closed"
                );
                continue;
            }

            // Get children
            let children = self.storage.get_child_nodes(&node.node_id)?;
            if children.is_empty() {
                debug!(node_id = %node.node_id, "Skipping node - no children");
                continue;
            }

            // Convert children to summaries
            let summaries: Vec<Summary> = children
                .iter()
                .map(|c| Summary::new(
                    c.title.clone(),
                    c.bullets.iter().map(|b| b.text.clone()).collect(),
                    c.keywords.clone(),
                ))
                .collect();

            // Generate rollup summary
            let rollup_summary = self.summarizer.summarize_children(&summaries).await?;

            // Update node with rollup summary
            let mut updated_node = node.clone();
            updated_node.title = rollup_summary.title;
            updated_node.bullets = rollup_summary.bullets
                .into_iter()
                .map(TocBullet::new)
                .collect();
            updated_node.keywords = rollup_summary.keywords;

            // Ensure child IDs are up to date
            updated_node.child_node_ids = children.iter().map(|c| c.node_id.clone()).collect();

            self.storage.put_toc_node(&updated_node)?;

            // Save checkpoint after each node
            self.save_checkpoint(&job_name, &updated_node)?;

            processed += 1;
            debug!(
                node_id = %updated_node.node_id,
                children = children.len(),
                "Rolled up node"
            );
        }

        info!(
            job = %job_name,
            processed = processed,
            "Rollup job complete"
        );

        Ok(processed)
    }

    /// Load checkpoint from storage.
    fn load_checkpoint(&self, job_name: &str) -> Result<Option<RollupCheckpoint>, RollupError> {
        match self.storage.get_checkpoint(job_name)? {
            Some(bytes) => {
                let checkpoint = RollupCheckpoint::from_bytes(&bytes)
                    .map_err(|e| RollupError::Checkpoint(e.to_string()))?;
                Ok(Some(checkpoint))
            }
            None => Ok(None),
        }
    }

    /// Save checkpoint to storage.
    fn save_checkpoint(&self, job_name: &str, node: &TocNode) -> Result<(), RollupError> {
        let checkpoint = RollupCheckpoint {
            job_name: job_name.to_string(),
            level: self.level,
            last_processed_time: node.end_time,
            processed_count: 1,
            created_at: Utc::now(),
        };

        let bytes = checkpoint.to_bytes()
            .map_err(|e| RollupError::Checkpoint(e.to_string()))?;

        self.storage.put_checkpoint(job_name, &bytes)?;
        Ok(())
    }
}

/// Run all rollup jobs in sequence.
pub async fn run_all_rollups(
    storage: Arc<Storage>,
    summarizer: Arc<dyn Summarizer>,
) -> Result<usize, RollupError> {
    let jobs = RollupJob::create_all(storage, summarizer);
    let mut total = 0;

    for job in jobs {
        total += job.run().await?;
    }

    Ok(total)
}

#[cfg(test)]
mod tests {
    use super::*;
    use memory_types::{Event, EventRole, EventType, Segment};
    use tempfile::TempDir;
    use chrono::TimeZone;
    use crate::summarizer::MockSummarizer;
    use crate::builder::TocBuilder;

    fn create_test_storage() -> (Arc<Storage>, TempDir) {
        let temp_dir = TempDir::new().unwrap();
        let storage = Arc::new(Storage::open(temp_dir.path()).unwrap());
        (storage, temp_dir)
    }

    fn create_test_event(text: &str, timestamp_ms: i64) -> Event {
        let ulid = ulid::Ulid::from_parts(timestamp_ms as u64, rand::random());
        Event::new(
            ulid.to_string(),
            "session-123".to_string(),
            Utc.timestamp_millis_opt(timestamp_ms).unwrap(),
            EventType::UserMessage,
            EventRole::User,
            text.to_string(),
        )
    }

    #[test]
    fn test_checkpoint_serialization() {
        let checkpoint = RollupCheckpoint::new("test_job".to_string(), TocLevel::Day);
        let bytes = checkpoint.to_bytes().unwrap();
        let decoded = RollupCheckpoint::from_bytes(&bytes).unwrap();

        assert_eq!(checkpoint.job_name, decoded.job_name);
        assert_eq!(checkpoint.level, decoded.level);
    }

    #[tokio::test]
    async fn test_rollup_job_no_children() {
        let (storage, _temp) = create_test_storage();
        let summarizer = Arc::new(MockSummarizer::new());

        let job = RollupJob::new(
            storage,
            summarizer,
            TocLevel::Day,
            Duration::zero(), // No min age for testing
        );

        let result = job.run().await.unwrap();
        assert_eq!(result, 0); // No nodes to process
    }

    #[tokio::test]
    async fn test_rollup_job_with_segments() {
        let (storage, _temp) = create_test_storage();
        let summarizer = Arc::new(MockSummarizer::new());

        // First, create some segments using TocBuilder
        let builder = TocBuilder::new(storage.clone(), summarizer.clone());

        // Create segment in the past
        let past_time = Utc::now() - Duration::days(2);
        let events = vec![
            Event::new(
                ulid::Ulid::new().to_string(),
                "session".to_string(),
                past_time,
                EventType::UserMessage,
                EventRole::User,
                "Test event".to_string(),
            ),
        ];
        let segment = Segment::new(
            "seg:test".to_string(),
            events.clone(),
            past_time,
            past_time,
            50,
        );

        builder.process_segment(&segment).await.unwrap();

        // Run rollup job
        let job = RollupJob::new(
            storage.clone(),
            summarizer,
            TocLevel::Day,
            Duration::hours(1),
        );

        let result = job.run().await.unwrap();
        // Result depends on whether the day node has children
        // This tests the basic flow works without errors
        assert!(result >= 0);
    }
}
```
  </action>
  <verify>
`cargo build -p memory-toc` compiles with rollup module.
`cargo test -p memory-toc -- --test rollup` passes.
  </verify>
  <done>
Rollup jobs aggregate child nodes with checkpoint-based crash recovery.
  </done>
</task>

</tasks>

<verification>
1. `cargo build -p memory-toc` compiles without errors
2. `cargo build -p memory-storage` compiles with TOC methods
3. `cargo test --workspace` passes all tests
4. TOC nodes stored with versioning (TOC-06)
5. Node IDs encode level and time period
6. TocBuilder creates segment nodes and parent hierarchy
7. RollupJob aggregates children with summarizer
8. Checkpoints enable crash recovery (STOR-03, TOC-05)
</verification>

<success_criteria>
- TOC nodes at all levels (Year, Month, Week, Day, Segment) - TOC-01
- Node IDs hierarchically structured
- Versioned node storage (TOC-06)
- Rollup jobs with checkpointing (TOC-05)
- Parent nodes created and linked
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-toc-building/02-03-SUMMARY.md`
</output>
