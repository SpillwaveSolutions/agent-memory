---
phase: 11-bm25-teleport-tantivy
plan: 02
type: execute
wave: 2
depends_on: ["11-01"]
files_modified:
  - crates/memory-search/src/indexer.rs
  - crates/memory-search/src/document.rs
  - crates/memory-search/src/lib.rs
autonomous: true

must_haves:
  truths:
    - "TOC nodes can be indexed with title, bullets, and keywords"
    - "Grips can be indexed with excerpt text"
    - "Documents can be updated (delete + re-add)"
    - "Index commits make documents searchable"
  artifacts:
    - path: "crates/memory-search/src/indexer.rs"
      provides: "SearchIndexer for adding/updating documents"
      exports: ["SearchIndexer"]
    - path: "crates/memory-search/src/document.rs"
      provides: "Document mapping from domain types"
      exports: ["toc_node_to_doc", "grip_to_doc"]
  key_links:
    - from: "crates/memory-search/src/indexer.rs"
      to: "tantivy::IndexWriter"
      via: "wraps writer with Arc<Mutex> for shared access"
      pattern: "Arc<Mutex<IndexWriter>>"
    - from: "crates/memory-search/src/document.rs"
      to: "memory_types::TocNode"
      via: "maps TocNode fields to Tantivy document"
      pattern: "TocNode"
    - from: "crates/memory-search/src/document.rs"
      to: "memory_types::Grip"
      via: "maps Grip fields to Tantivy document"
      pattern: "Grip"
---

<objective>
Implement the indexing pipeline for TOC nodes and grips.

Purpose: Enable documents to be added to the search index so they become searchable via BM25.
Output: SearchIndexer with methods for indexing TOC nodes and grips, plus document mapping functions.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/11-bm25-teleport-tantivy/11-RESEARCH.md
@.planning/phases/11-bm25-teleport-tantivy/11-01-SUMMARY.md
@crates/memory-search/src/schema.rs
@crates/memory-search/src/index.rs
@crates/memory-types/src/toc.rs
@crates/memory-types/src/grip.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create document mapping functions</name>
  <files>
    crates/memory-search/src/document.rs
    crates/memory-search/src/lib.rs
  </files>
  <action>
Create document mapping from domain types to Tantivy documents:

1. Create `crates/memory-search/src/document.rs`:
   ```rust
   //! Document mapping from domain types to Tantivy documents.
   //!
   //! Converts TocNode and Grip into indexable Tantivy documents.

   use tantivy::doc;
   use tantivy::schema::Document;

   use memory_types::{Grip, TocNode};

   use crate::schema::{DocType, SearchSchema};

   /// Convert a TocNode to a Tantivy document.
   ///
   /// Text field contains: title + all bullet texts
   /// Keywords field contains: joined keywords
   pub fn toc_node_to_doc(schema: &SearchSchema, node: &TocNode) -> Document {
       // Combine title and bullets for searchable text
       let mut text_parts = vec![node.title.clone()];
       for bullet in &node.bullets {
           text_parts.push(bullet.text.clone());
       }
       let text = text_parts.join(" ");

       // Join keywords with space
       let keywords = node.keywords.join(" ");

       // Timestamp in milliseconds
       let timestamp = node.start_time.timestamp_millis().to_string();

       doc!(
           schema.doc_type => DocType::TocNode.as_str(),
           schema.doc_id => node.node_id.clone(),
           schema.level => node.level.to_string(),
           schema.text => text,
           schema.keywords => keywords,
           schema.timestamp_ms => timestamp
       )
   }

   /// Convert a Grip to a Tantivy document.
   ///
   /// Text field contains: excerpt
   /// Level field is empty (not applicable to grips)
   pub fn grip_to_doc(schema: &SearchSchema, grip: &Grip) -> Document {
       let timestamp = grip.timestamp.timestamp_millis().to_string();

       doc!(
           schema.doc_type => DocType::Grip.as_str(),
           schema.doc_id => grip.grip_id.clone(),
           schema.level => "",  // Not applicable for grips
           schema.text => grip.excerpt.clone(),
           schema.keywords => "",  // Grips don't have keywords
           schema.timestamp_ms => timestamp
       )
   }

   /// Extract text content from a TocNode for indexing.
   ///
   /// Returns combined title and bullet text.
   pub fn extract_toc_text(node: &TocNode) -> String {
       let mut parts = vec![node.title.clone()];
       for bullet in &node.bullets {
           parts.push(bullet.text.clone());
       }
       parts.join(" ")
   }

   #[cfg(test)]
   mod tests {
       use super::*;
       use crate::schema::build_teleport_schema;
       use chrono::Utc;
       use memory_types::{TocBullet, TocLevel};

       fn sample_toc_node() -> TocNode {
           let mut node = TocNode::new(
               "toc:day:2024-01-15".to_string(),
               TocLevel::Day,
               "Monday, January 15, 2024".to_string(),
               Utc::now(),
               Utc::now(),
           );
           node.bullets = vec![
               TocBullet::new("Discussed Rust memory safety"),
               TocBullet::new("Implemented authentication flow"),
           ];
           node.keywords = vec!["rust".to_string(), "memory".to_string(), "auth".to_string()];
           node
       }

       fn sample_grip() -> Grip {
           Grip::new(
               "grip-12345".to_string(),
               "User asked about borrow checker semantics".to_string(),
               "event-001".to_string(),
               "event-003".to_string(),
               Utc::now(),
               "segment_summarizer".to_string(),
           )
       }

       #[test]
       fn test_toc_node_to_doc() {
           let schema = build_teleport_schema();
           let node = sample_toc_node();

           let doc = toc_node_to_doc(&schema, &node);

           // Verify doc_type
           let doc_type = doc.get_first(schema.doc_type).unwrap();
           assert_eq!(doc_type.as_str(), Some("toc_node"));

           // Verify doc_id
           let doc_id = doc.get_first(schema.doc_id).unwrap();
           assert_eq!(doc_id.as_str(), Some("toc:day:2024-01-15"));

           // Verify text contains title and bullets
           let text = doc.get_first(schema.text).unwrap();
           let text_str = text.as_str().unwrap();
           assert!(text_str.contains("Monday, January 15, 2024"));
           assert!(text_str.contains("Rust memory safety"));
       }

       #[test]
       fn test_grip_to_doc() {
           let schema = build_teleport_schema();
           let grip = sample_grip();

           let doc = grip_to_doc(&schema, &grip);

           let doc_type = doc.get_first(schema.doc_type).unwrap();
           assert_eq!(doc_type.as_str(), Some("grip"));

           let text = doc.get_first(schema.text).unwrap();
           assert!(text.as_str().unwrap().contains("borrow checker"));
       }

       #[test]
       fn test_extract_toc_text() {
           let node = sample_toc_node();
           let text = extract_toc_text(&node);

           assert!(text.contains("Monday, January 15, 2024"));
           assert!(text.contains("Discussed Rust memory safety"));
           assert!(text.contains("Implemented authentication flow"));
       }
   }
   ```

2. Update lib.rs to export document module:
   ```rust
   pub mod document;
   pub use document::{toc_node_to_doc, grip_to_doc, extract_toc_text};
   ```
  </action>
  <verify>
    cd /Users/richardhightower/clients/spillwave/src/agent-memory && cargo test -p memory-search document
  </verify>
  <done>
    Document mapping functions convert TocNode and Grip to Tantivy documents correctly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement SearchIndexer with shared writer</name>
  <files>
    crates/memory-search/src/indexer.rs
    crates/memory-search/src/lib.rs
  </files>
  <action>
Create the SearchIndexer that manages document indexing:

1. Create `crates/memory-search/src/indexer.rs`:
   ```rust
   //! Search indexer for adding documents to the Tantivy index.
   //!
   //! The indexer wraps IndexWriter with shared access via Arc<Mutex>.
   //! Documents are not visible until commit() is called.

   use std::sync::{Arc, Mutex};

   use tantivy::{IndexWriter, Term};
   use tracing::{debug, info, warn};

   use memory_types::{Grip, TocNode};

   use crate::document::{grip_to_doc, toc_node_to_doc};
   use crate::error::SearchError;
   use crate::index::SearchIndex;
   use crate::schema::SearchSchema;

   /// Manages document indexing operations.
   ///
   /// Wraps IndexWriter for shared access across components.
   /// Commit batches documents for visibility.
   pub struct SearchIndexer {
       writer: Arc<Mutex<IndexWriter>>,
       schema: SearchSchema,
   }

   impl SearchIndexer {
       /// Create a new indexer from a SearchIndex.
       pub fn new(index: &SearchIndex) -> Result<Self, SearchError> {
           let writer = index.writer()?;
           let schema = index.schema().clone();

           Ok(Self {
               writer: Arc::new(Mutex::new(writer)),
               schema,
           })
       }

       /// Create from an existing writer (for testing or shared use).
       pub fn from_writer(writer: IndexWriter, schema: SearchSchema) -> Self {
           Self {
               writer: Arc::new(Mutex::new(writer)),
               schema,
           }
       }

       /// Get a clone of the writer Arc for sharing.
       pub fn writer_handle(&self) -> Arc<Mutex<IndexWriter>> {
           self.writer.clone()
       }

       /// Index a TOC node.
       ///
       /// If a document with the same node_id exists, it will be replaced.
       pub fn index_toc_node(&self, node: &TocNode) -> Result<(), SearchError> {
           let doc = toc_node_to_doc(&self.schema, node);

           let mut writer = self.writer.lock()
               .map_err(|e| SearchError::IndexLocked(e.to_string()))?;

           // Delete existing document with same ID (for update)
           let term = Term::from_field_text(self.schema.doc_id, &node.node_id);
           writer.delete_term(term);

           // Add new document
           writer.add_document(doc)?;

           debug!(node_id = %node.node_id, level = %node.level, "Indexed TOC node");
           Ok(())
       }

       /// Index a grip.
       ///
       /// If a document with the same grip_id exists, it will be replaced.
       pub fn index_grip(&self, grip: &Grip) -> Result<(), SearchError> {
           let doc = grip_to_doc(&self.schema, grip);

           let mut writer = self.writer.lock()
               .map_err(|e| SearchError::IndexLocked(e.to_string()))?;

           // Delete existing document with same ID (for update)
           let term = Term::from_field_text(self.schema.doc_id, &grip.grip_id);
           writer.delete_term(term);

           // Add new document
           writer.add_document(doc)?;

           debug!(grip_id = %grip.grip_id, "Indexed grip");
           Ok(())
       }

       /// Index multiple TOC nodes in batch.
       pub fn index_toc_nodes(&self, nodes: &[TocNode]) -> Result<usize, SearchError> {
           let mut writer = self.writer.lock()
               .map_err(|e| SearchError::IndexLocked(e.to_string()))?;

           let mut count = 0;
           for node in nodes {
               let doc = toc_node_to_doc(&self.schema, node);

               // Delete existing
               let term = Term::from_field_text(self.schema.doc_id, &node.node_id);
               writer.delete_term(term);

               // Add new
               writer.add_document(doc)?;
               count += 1;
           }

           debug!(count, "Indexed TOC nodes batch");
           Ok(count)
       }

       /// Index multiple grips in batch.
       pub fn index_grips(&self, grips: &[Grip]) -> Result<usize, SearchError> {
           let mut writer = self.writer.lock()
               .map_err(|e| SearchError::IndexLocked(e.to_string()))?;

           let mut count = 0;
           for grip in grips {
               let doc = grip_to_doc(&self.schema, grip);

               // Delete existing
               let term = Term::from_field_text(self.schema.doc_id, &grip.grip_id);
               writer.delete_term(term);

               // Add new
               writer.add_document(doc)?;
               count += 1;
           }

           debug!(count, "Indexed grips batch");
           Ok(count)
       }

       /// Delete a document by ID.
       pub fn delete_document(&self, doc_id: &str) -> Result<(), SearchError> {
           let mut writer = self.writer.lock()
               .map_err(|e| SearchError::IndexLocked(e.to_string()))?;

           let term = Term::from_field_text(self.schema.doc_id, doc_id);
           writer.delete_term(term);

           debug!(doc_id, "Deleted document");
           Ok(())
       }

       /// Commit pending changes to make them searchable.
       ///
       /// This is expensive - batch document adds and commit periodically.
       pub fn commit(&self) -> Result<u64, SearchError> {
           let mut writer = self.writer.lock()
               .map_err(|e| SearchError::IndexLocked(e.to_string()))?;

           let opstamp = writer.commit()?;
           info!(opstamp, "Committed index changes");
           Ok(opstamp)
       }

       /// Rollback uncommitted changes.
       pub fn rollback(&self) -> Result<u64, SearchError> {
           let mut writer = self.writer.lock()
               .map_err(|e| SearchError::IndexLocked(e.to_string()))?;

           let opstamp = writer.rollback()?;
           warn!(opstamp, "Rolled back index changes");
           Ok(opstamp)
       }

       /// Get pending document count (approximate).
       pub fn pending_ops(&self) -> Result<u64, SearchError> {
           let writer = self.writer.lock()
               .map_err(|e| SearchError::IndexLocked(e.to_string()))?;

           Ok(writer.opstamp())
       }
   }

   #[cfg(test)]
   mod tests {
       use super::*;
       use crate::index::{SearchIndex, SearchIndexConfig};
       use chrono::Utc;
       use memory_types::{TocBullet, TocLevel};
       use tempfile::TempDir;

       fn sample_toc_node(id: &str) -> TocNode {
           let mut node = TocNode::new(
               id.to_string(),
               TocLevel::Day,
               format!("Test Node {}", id),
               Utc::now(),
               Utc::now(),
           );
           node.bullets = vec![TocBullet::new("Test bullet content")];
           node.keywords = vec!["test".to_string()];
           node
       }

       fn sample_grip(id: &str) -> Grip {
           Grip::new(
               id.to_string(),
               "Test excerpt content".to_string(),
               "event-001".to_string(),
               "event-002".to_string(),
               Utc::now(),
               "test".to_string(),
           )
       }

       #[test]
       fn test_index_toc_node() {
           let temp_dir = TempDir::new().unwrap();
           let config = SearchIndexConfig::new(temp_dir.path());
           let index = SearchIndex::open_or_create(config).unwrap();
           let indexer = SearchIndexer::new(&index).unwrap();

           let node = sample_toc_node("node-1");
           indexer.index_toc_node(&node).unwrap();
           indexer.commit().unwrap();
       }

       #[test]
       fn test_index_grip() {
           let temp_dir = TempDir::new().unwrap();
           let config = SearchIndexConfig::new(temp_dir.path());
           let index = SearchIndex::open_or_create(config).unwrap();
           let indexer = SearchIndexer::new(&index).unwrap();

           let grip = sample_grip("grip-1");
           indexer.index_grip(&grip).unwrap();
           indexer.commit().unwrap();
       }

       #[test]
       fn test_index_batch() {
           let temp_dir = TempDir::new().unwrap();
           let config = SearchIndexConfig::new(temp_dir.path());
           let index = SearchIndex::open_or_create(config).unwrap();
           let indexer = SearchIndexer::new(&index).unwrap();

           let nodes: Vec<TocNode> = (0..5)
               .map(|i| sample_toc_node(&format!("node-{}", i)))
               .collect();

           let count = indexer.index_toc_nodes(&nodes).unwrap();
           assert_eq!(count, 5);
           indexer.commit().unwrap();
       }

       #[test]
       fn test_update_existing_document() {
           let temp_dir = TempDir::new().unwrap();
           let config = SearchIndexConfig::new(temp_dir.path());
           let index = SearchIndex::open_or_create(config).unwrap();
           let indexer = SearchIndexer::new(&index).unwrap();

           // Index initial version
           let mut node = sample_toc_node("node-1");
           node.title = "Version 1".to_string();
           indexer.index_toc_node(&node).unwrap();
           indexer.commit().unwrap();

           // Index updated version (same ID)
           node.title = "Version 2".to_string();
           node.version = 2;
           indexer.index_toc_node(&node).unwrap();
           indexer.commit().unwrap();

           // Should only have one document
           let reader = index.reader().unwrap();
           let searcher = reader.searcher();
           let num_docs: u64 = searcher.segment_readers()
               .iter()
               .map(|r| r.num_docs() as u64)
               .sum();
           assert_eq!(num_docs, 1);
       }
   }
   ```

2. Update lib.rs exports:
   ```rust
   pub mod indexer;
   pub use indexer::SearchIndexer;
   ```
  </action>
  <verify>
    cd /Users/richardhightower/clients/spillwave/src/agent-memory && cargo test -p memory-search indexer
  </verify>
  <done>
    SearchIndexer indexes TOC nodes and grips. Update/delete works via term deletion. Commit makes changes visible.
  </done>
</task>

</tasks>

<verification>
```bash
cd /Users/richardhightower/clients/spillwave/src/agent-memory

# All document tests pass
cargo test -p memory-search document

# All indexer tests pass
cargo test -p memory-search indexer

# Full crate tests
cargo test -p memory-search

# Clippy clean
cargo clippy -p memory-search -- -D warnings
```
</verification>

<success_criteria>
- [ ] toc_node_to_doc maps title, bullets, keywords to document fields
- [ ] grip_to_doc maps excerpt to document text field
- [ ] SearchIndexer wraps IndexWriter with Arc<Mutex>
- [ ] index_toc_node and index_grip add documents
- [ ] Update replaces existing document (delete + add pattern)
- [ ] commit() makes documents searchable
- [ ] Batch indexing methods work correctly
- [ ] All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/11-bm25-teleport-tantivy/11-02-SUMMARY.md`
</output>
