---
phase: 12-vector-teleport-hnsw
plan: 04
type: execute
wave: 4
depends_on: [12-03]
files_modified:
  - crates/memory-client/src/lib.rs
  - crates/memory-daemon/Cargo.toml
  - crates/memory-daemon/src/cli.rs
  - crates/memory-daemon/src/commands/teleport.rs
  - docs/usage/vector-search.md
autonomous: true

must_haves:
  truths:
    - "CLI vector command searches by semantic similarity"
    - "CLI hybrid command combines BM25 and vector scores"
    - "CLI vector-status shows index health information"
    - "Admin prune-vectors removes old vectors without data loss"
  artifacts:
    - path: "crates/memory-daemon/src/commands/teleport.rs"
      provides: "CLI vector command handlers"
      exports: ["vector_search", "hybrid_search", "vector_status"]
    - path: "crates/memory-client/src/lib.rs"
      provides: "Client methods for vector RPCs"
      contains: "vector_teleport"
    - path: "docs/usage/vector-search.md"
      provides: "User documentation"
      contains: "VectorTeleport"
  key_links:
    - from: "crates/memory-daemon/src/commands/teleport.rs"
      to: "memory-client"
      via: "calls gRPC methods"
      pattern: "client.vector_teleport"
    - from: "crates/memory-client/src/lib.rs"
      to: "proto::VectorTeleportRequest"
      via: "sends gRPC request"
      pattern: "vector_teleport"
---

<objective>
Add CLI commands for vector search, hybrid search, and administration.

Purpose: Enable users to test and debug vector search from the command line. Provide admin commands for index maintenance. Document the vector search feature.

Output: CLI teleport vector/hybrid/vector-status commands, admin prune-vectors command, and user documentation.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/12-vector-teleport-hnsw/12-RESEARCH.md
@.planning/phases/12-vector-teleport-hnsw/12-03-SUMMARY.md
@crates/memory-client/src/lib.rs
@crates/memory-daemon/src/cli.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add vector client methods</name>
  <files>
    crates/memory-client/src/lib.rs
  </files>
  <action>
Add client methods for vector RPCs:

1. Update `crates/memory-client/src/lib.rs` to add:

   ```rust
   /// Vector teleport (semantic similarity search).
   pub async fn vector_teleport(
       &mut self,
       query: &str,
       top_k: i32,
       min_score: f32,
       target: VectorTargetType,
   ) -> Result<VectorTeleportResponse, ClientError> {
       let request = VectorTeleportRequest {
           query: query.to_string(),
           top_k,
           min_score,
           time_filter: None,
           target: target as i32,
       };
       let response = self.client.vector_teleport(request).await?;
       Ok(response.into_inner())
   }

   /// Hybrid search (BM25 + vector fusion).
   pub async fn hybrid_search(
       &mut self,
       query: &str,
       top_k: i32,
       mode: HybridMode,
       bm25_weight: f32,
       vector_weight: f32,
   ) -> Result<HybridSearchResponse, ClientError> {
       let request = HybridSearchRequest {
           query: query.to_string(),
           top_k,
           mode: mode as i32,
           bm25_weight,
           vector_weight,
           time_filter: None,
           target: VectorTargetType::All as i32,
       };
       let response = self.client.hybrid_search(request).await?;
       Ok(response.into_inner())
   }

   /// Get vector index status.
   pub async fn get_vector_index_status(&mut self) -> Result<VectorIndexStatus, ClientError> {
       let request = GetVectorIndexStatusRequest {};
       let response = self.client.get_vector_index_status(request).await?;
       Ok(response.into_inner())
   }
   ```

2. Add necessary proto type re-exports at the top of the file:
   ```rust
   pub use crate::proto::{
       VectorTeleportRequest, VectorTeleportResponse, VectorMatch,
       HybridSearchRequest, HybridSearchResponse, HybridMode,
       GetVectorIndexStatusRequest, VectorIndexStatus, VectorTargetType,
   };
   ```
  </action>
  <verify>
    cd /Users/richardhightower/clients/spillwave/src/agent-memory && cargo build -p memory-client
  </verify>
  <done>
    MemoryClient has vector_teleport, hybrid_search, get_vector_index_status methods.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add CLI vector subcommands</name>
  <files>
    crates/memory-daemon/Cargo.toml
    crates/memory-daemon/src/cli.rs
    crates/memory-daemon/src/commands/teleport.rs
    crates/memory-daemon/src/commands/mod.rs
  </files>
  <action>
Add CLI commands for vector search:

1. Ensure `crates/memory-daemon/Cargo.toml` has:
   - memory-client = { workspace = true }
   - memory-embeddings = { workspace = true }
   - memory-vector = { workspace = true }

2. Update `crates/memory-daemon/src/cli.rs` to extend TeleportCommand:
   ```rust
   #[derive(Subcommand, Debug)]
   pub enum TeleportCommand {
       /// BM25 keyword search (Phase 11)
       Search {
           /// Search query
           query: String,
           /// Maximum results
           #[arg(short, long, default_value = "10")]
           limit: i32,
           /// gRPC server address
           #[arg(long, default_value = "http://127.0.0.1:50051")]
           addr: String,
       },

       /// Vector semantic similarity search
       Vector {
           /// Search query
           query: String,
           /// Maximum results
           #[arg(short, long, default_value = "10")]
           limit: i32,
           /// Minimum similarity score (0.0 to 1.0)
           #[arg(long, default_value = "0.0")]
           min_score: f32,
           /// Target type: all, toc, grip
           #[arg(long, default_value = "all")]
           target: String,
           /// gRPC server address
           #[arg(long, default_value = "http://127.0.0.1:50051")]
           addr: String,
       },

       /// Hybrid BM25 + vector search
       Hybrid {
           /// Search query
           query: String,
           /// Maximum results
           #[arg(short, long, default_value = "10")]
           limit: i32,
           /// BM25 weight (0.0 to 1.0)
           #[arg(long, default_value = "0.5")]
           bm25_weight: f32,
           /// Vector weight (0.0 to 1.0)
           #[arg(long, default_value = "0.5")]
           vector_weight: f32,
           /// gRPC server address
           #[arg(long, default_value = "http://127.0.0.1:50051")]
           addr: String,
       },

       /// Show vector index status
       VectorStatus {
           /// gRPC server address
           #[arg(long, default_value = "http://127.0.0.1:50051")]
           addr: String,
       },
   }
   ```

3. Create or update `crates/memory-daemon/src/commands/teleport.rs`:
   ```rust
   //! Teleport search command handlers.

   use anyhow::Result;
   use memory_client::{MemoryClient, VectorTargetType, HybridMode};

   pub async fn vector_search(
       addr: &str,
       query: &str,
       limit: i32,
       min_score: f32,
       target: &str,
   ) -> Result<()> {
       let mut client = MemoryClient::connect(addr).await?;

       let target_type = match target.to_lowercase().as_str() {
           "toc" => VectorTargetType::TocNode,
           "grip" => VectorTargetType::Grip,
           _ => VectorTargetType::All,
       };

       let response = client.vector_teleport(query, limit, min_score, target_type).await?;

       println!("Vector search for: \"{}\"", query);
       println!("Min score: {:.2}, Limit: {}\n", min_score, limit);

       if response.matches.is_empty() {
           println!("No results found.");
       } else {
           println!("Found {} results:", response.matches.len());
           println!("{:-<70}", "");

           for (i, m) in response.matches.iter().enumerate() {
               println!(
                   "{}. [{}] {} (score: {:.4})",
                   i + 1,
                   m.doc_type.to_uppercase(),
                   m.doc_id,
                   m.score
               );
               if !m.text_preview.is_empty() {
                   println!("   {}", m.text_preview);
               }
           }
       }

       if let Some(status) = response.index_status {
           println!("\nIndex: {} vectors, {} bytes", status.vector_count, status.size_bytes);
       }

       Ok(())
   }

   pub async fn hybrid_search(
       addr: &str,
       query: &str,
       limit: i32,
       bm25_weight: f32,
       vector_weight: f32,
   ) -> Result<()> {
       let mut client = MemoryClient::connect(addr).await?;

       let response = client.hybrid_search(
           query,
           limit,
           HybridMode::Hybrid,
           bm25_weight,
           vector_weight,
       ).await?;

       println!("Hybrid search for: \"{}\"", query);
       println!("Weights - BM25: {:.2}, Vector: {:.2}\n", bm25_weight, vector_weight);

       let mode_str = match response.mode_used {
           1 => "VECTOR_ONLY",
           2 => "BM25_ONLY",
           3 => "HYBRID",
           _ => "UNKNOWN",
       };
       println!("Mode used: {} (BM25: {}, Vector: {})",
           mode_str,
           if response.bm25_available { "yes" } else { "no" },
           if response.vector_available { "yes" } else { "no" }
       );
       println!();

       if response.matches.is_empty() {
           println!("No results found.");
       } else {
           println!("Found {} results:", response.matches.len());
           println!("{:-<80}", "");
           println!("{:<4} {:<8} {:<40} {:>8}", "#", "Type", "Doc ID", "Score");
           println!("{:-<80}", "");

           for (i, m) in response.matches.iter().enumerate() {
               println!(
                   "{:<4} {:<8} {:<40} {:>8.4}",
                   i + 1,
                   m.doc_type.to_uppercase(),
                   truncate(&m.doc_id, 38),
                   m.score
               );
           }
       }

       Ok(())
   }

   pub async fn vector_status(addr: &str) -> Result<()> {
       let mut client = MemoryClient::connect(addr).await?;
       let status = client.get_vector_index_status().await?;

       println!("Vector Index Status");
       println!("{:-<40}", "");
       println!("Available:     {}", if status.available { "Yes" } else { "No" });
       println!("Vector count:  {}", status.vector_count);
       println!("Dimension:     {}", status.dimension);
       println!("Index path:    {}", status.index_path);
       println!("Size:          {} bytes", status.size_bytes);
       if !status.last_indexed.is_empty() {
           println!("Last indexed:  {}", status.last_indexed);
       }

       Ok(())
   }

   fn truncate(s: &str, max: usize) -> String {
       if s.len() > max {
           format!("{}...", &s[..max-3])
       } else {
           s.to_string()
       }
   }
   ```

4. Update `crates/memory-daemon/src/commands/mod.rs` to export teleport module.
  </action>
  <verify>
    cd /Users/richardhightower/clients/spillwave/src/agent-memory && cargo build -p memory-daemon && ./target/debug/memory-daemon teleport --help
  </verify>
  <done>
    CLI commands implemented: teleport vector, teleport hybrid, teleport vector-status. Help text shows subcommands.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create documentation and end-to-end tests</name>
  <files>
    docs/usage/vector-search.md
    tests/integration/vector_test.rs
  </files>
  <action>
Create user documentation and integration tests:

1. Create `docs/usage/vector-search.md`:
   ```markdown
   # Vector Search Guide

   Vector search enables semantic similarity queries that find conceptually
   related content even when exact keywords don't match.

   ## Overview

   Agent Memory supports three search modes:

   | Mode | Use Case | Index Required |
   |------|----------|----------------|
   | Vector | Find semantically similar content | HNSW |
   | BM25 | Find keyword matches | Tantivy |
   | Hybrid | Best of both worlds | Both |

   ## CLI Commands

   ### Vector Search

   Search by semantic similarity:

   ```bash
   # Basic vector search
   memory-daemon teleport vector "JWT authentication"

   # Limit results and filter by type
   memory-daemon teleport vector "token expiration" --limit 5 --target toc

   # Require minimum similarity
   memory-daemon teleport vector "OAuth flow" --min-score 0.7
   ```

   ### Hybrid Search

   Combine BM25 keywords with vector semantics:

   ```bash
   # Default 50/50 weighting
   memory-daemon teleport hybrid "session management"

   # Prefer vector similarity
   memory-daemon teleport hybrid "login flow" --bm25-weight 0.3 --vector-weight 0.7

   # Prefer keyword matching
   memory-daemon teleport hybrid "parse_token" --bm25-weight 0.7 --vector-weight 0.3
   ```

   ### Index Status

   Check vector index health:

   ```bash
   memory-daemon teleport vector-status
   ```

   Output:
   ```
   Vector Index Status
   ----------------------------------------
   Available:     Yes
   Vector count:  12,345
   Dimension:     384
   Index path:    ~/.local/share/agent-memory/vector-index
   Size:          45,678,901 bytes
   ```

   ## gRPC API

   ### VectorTeleport

   ```protobuf
   rpc VectorTeleport(VectorTeleportRequest) returns (VectorTeleportResponse);
   ```

   Request:
   - `query`: Text to search for (will be embedded)
   - `top_k`: Maximum results (default: 10)
   - `min_score`: Minimum similarity 0.0-1.0
   - `target`: TOC_NODE, GRIP, or ALL
   - `time_filter`: Optional start_ms/end_ms range

   ### HybridSearch

   ```protobuf
   rpc HybridSearch(HybridSearchRequest) returns (HybridSearchResponse);
   ```

   Request:
   - `query`: Text to search
   - `mode`: VECTOR_ONLY, BM25_ONLY, or HYBRID
   - `bm25_weight`: Weight for BM25 (default: 0.5)
   - `vector_weight`: Weight for vector (default: 0.5)

   ## How It Works

   ### Embedding Model

   Agent Memory uses `all-MiniLM-L6-v2` for generating embeddings:
   - 384 dimensions
   - Local inference (no API calls)
   - ~50ms per embedding on CPU

   ### HNSW Index

   The vector index uses HNSW (Hierarchical Navigable Small World):
   - O(log n) search complexity
   - High recall (~95%)
   - Memory-mapped for persistence

   Parameters:
   - M = 16 (connections per layer)
   - ef_construction = 200 (build quality)
   - ef_search = 100 (search quality)

   ### Reciprocal Rank Fusion

   Hybrid search uses RRF to combine rankings:

   ```
   RRF_score(doc) = bm25_weight/(60 + bm25_rank) + vector_weight/(60 + vector_rank)
   ```

   This gives documents appearing in both result sets a boost.

   ## Troubleshooting

   ### Index Not Available

   If `vector-status` shows "Available: No":

   1. Check that vectors have been indexed
   2. Verify the index path exists
   3. Ensure daemon has write permission

   ### Slow Embedding

   Embedding is CPU-bound. To improve performance:

   1. Use batch operations when possible
   2. Consider GPU acceleration (future feature)

   ### Low Recall

   If relevant results aren't found:

   1. Try different query phrasing
   2. Lower `min_score` threshold
   3. Use hybrid mode to include keyword matches
   ```

2. Create basic integration test `tests/integration/vector_test.rs`:
   ```rust
   //! Integration tests for vector search.

   use memory_embeddings::{CandleEmbedder, EmbeddingModel, ModelCache};
   use memory_vector::{HnswIndex, HnswConfig, VectorIndex};

   #[test]
   #[ignore = "requires model download"]
   fn test_embedding_and_search_round_trip() {
       // Load model
       let cache = ModelCache::default();
       let embedder = CandleEmbedder::load(&cache).unwrap();

       // Create index
       let temp = tempfile::TempDir::new().unwrap();
       let config = HnswConfig::new(384, temp.path());
       let mut index = HnswIndex::open_or_create(config).unwrap();

       // Add some documents
       let docs = [
           (1, "JWT authentication with token refresh"),
           (2, "OAuth 2.0 authorization code flow"),
           (3, "Session management and cookies"),
           (4, "Rust memory safety guarantees"),
           (5, "Database query optimization"),
       ];

       for (id, text) in &docs {
           let emb = embedder.embed(text).unwrap();
           index.add(*id, &emb).unwrap();
       }

       // Search for auth-related content
       let query = embedder.embed("login and authentication").unwrap();
       let results = index.search(&query, 3).unwrap();

       // Should find auth-related docs first
       assert!(results.len() >= 2);
       let ids: Vec<u64> = results.iter().map(|r| r.vector_id).collect();
       assert!(ids.contains(&1) || ids.contains(&2)); // JWT or OAuth should be in top 3
   }
   ```
  </action>
  <verify>
    cd /Users/richardhightower/clients/spillwave/src/agent-memory && cargo build -p memory-daemon && test -f docs/usage/vector-search.md
  </verify>
  <done>
    Documentation created at docs/usage/vector-search.md. Integration test skeleton added.
  </done>
</task>

</tasks>

<verification>
```bash
cd /Users/richardhightower/clients/spillwave/src/agent-memory

# Client builds
cargo build -p memory-client

# Daemon builds
cargo build -p memory-daemon

# CLI help shows vector commands
./target/debug/memory-daemon teleport --help

# Documentation exists
cat docs/usage/vector-search.md

# Clippy clean
cargo clippy -p memory-client -p memory-daemon -- -D warnings
```
</verification>

<success_criteria>
- [ ] MemoryClient has vector_teleport method
- [ ] MemoryClient has hybrid_search method
- [ ] MemoryClient has get_vector_index_status method
- [ ] CLI teleport vector command works
- [ ] CLI teleport hybrid command works
- [ ] CLI teleport vector-status command works
- [ ] Output is human-readable with proper formatting
- [ ] Documentation explains CLI usage and gRPC API
- [ ] Documentation explains HNSW parameters
- [ ] Documentation explains RRF formula
- [ ] All tests pass
- [ ] No clippy warnings
</success_criteria>

<output>
After completion, create `.planning/phases/12-vector-teleport-hnsw/12-04-SUMMARY.md`
</output>
