---
phase: 16-memory-ranking-enhancements
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - crates/memory-storage/src/column_families.rs
  - crates/memory-storage/src/lib.rs
  - crates/memory-storage/src/usage.rs
  - crates/memory-types/src/usage.rs
  - crates/memory-types/src/lib.rs
  - crates/memory-types/src/config.rs
autonomous: true

must_haves:
  truths:
    - "Usage counters are stored in separate CF_USAGE_COUNTERS column family"
    - "Cache-first reads return cached data immediately without blocking on CF read"
    - "Pending writes are batched and flushed every 60 seconds"
    - "Cache misses return default (count=0) and queue prefetch"
    - "LRU cache bounded to configurable size (default 10K entries)"
  artifacts:
    - path: "crates/memory-storage/src/usage.rs"
      provides: "UsageTracker with cache-first reads and batched writes"
      exports: ["UsageTracker", "UsageStats", "UsageConfig"]
    - path: "crates/memory-storage/src/column_families.rs"
      provides: "CF_USAGE_COUNTERS constant"
      contains: "CF_USAGE_COUNTERS"
    - path: "crates/memory-types/src/usage.rs"
      provides: "UsageStats and UsageConfig types"
      exports: ["UsageStats", "UsageConfig"]
  key_links:
    - from: "crates/memory-storage/src/usage.rs"
      to: "crates/memory-storage/src/column_families.rs"
      via: "uses CF_USAGE_COUNTERS constant"
      pattern: "CF_USAGE_COUNTERS"
---

<objective>
Implement usage counter infrastructure with cache-first reads and batched writes.

Purpose: Track memory access patterns WITHOUT mutating immutable TOC nodes or Grips. Usage data lives in separate column family CF_USAGE_COUNTERS. Cache-first design ensures no search latency impact.

Output: UsageTracker service with LRU cache, batched CF writes, and async prefetch for cache misses.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Technical reference
@docs/plans/phase-16-memory-ranking-plan.md
@crates/memory-storage/src/column_families.rs
@crates/memory-storage/src/lib.rs
@crates/memory-storage/src/db.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add CF_USAGE_COUNTERS to column families</name>
  <files>crates/memory-storage/src/column_families.rs</files>
  <action>
Update `crates/memory-storage/src/column_families.rs`:

1. Add constant (after CF_TOPIC_RELS):
   ```rust
   /// Column family for usage counters (access count, last accessed)
   pub const CF_USAGE_COUNTERS: &str = "usage_counters";
   ```

2. Add to ALL_CF_NAMES array (order doesn't matter, add at end):
   ```rust
   pub const ALL_CF_NAMES: &[&str] = &[
       CF_EVENTS,
       CF_TOC_NODES,
       CF_TOC_LATEST,
       CF_GRIPS,
       CF_OUTBOX,
       CF_CHECKPOINTS,
       CF_TOPICS,
       CF_TOPIC_LINKS,
       CF_TOPIC_RELS,
       CF_USAGE_COUNTERS,  // NEW
   ];
   ```

3. Add to build_cf_descriptors() function:
   ```rust
   ColumnFamilyDescriptor::new(CF_USAGE_COUNTERS, Options::default()),
   ```
  </action>
  <verify>
```bash
cargo build -p memory-storage
cargo test -p memory-storage
```
  </verify>
  <done>CF_USAGE_COUNTERS constant exists and is included in ALL_CF_NAMES and build_cf_descriptors</done>
</task>

<task type="auto">
  <name>Task 2: Create UsageStats and UsageConfig types in memory-types</name>
  <files>crates/memory-types/src/usage.rs, crates/memory-types/src/lib.rs, crates/memory-types/src/config.rs</files>
  <action>
Create new file `crates/memory-types/src/usage.rs`:

```rust
//! Usage tracking types for access pattern analysis.
//!
//! Per Phase 16 Plan 02: Track access patterns WITHOUT mutating immutable nodes.
//! Usage data stored separately in CF_USAGE_COUNTERS.

use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};

/// Usage statistics for a document (TOC node, grip, topic)
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct UsageStats {
    /// Number of times this document was accessed
    pub access_count: u32,
    /// Last access timestamp (None if never accessed)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub last_accessed: Option<DateTime<Utc>>,
}

impl UsageStats {
    /// Create new usage stats with zero access
    pub fn new() -> Self {
        Self::default()
    }

    /// Increment access count and update timestamp
    pub fn record_access(&mut self) {
        self.access_count = self.access_count.saturating_add(1);
        self.last_accessed = Some(Utc::now());
    }

    /// Serialize to JSON bytes
    pub fn to_bytes(&self) -> Result<Vec<u8>, serde_json::Error> {
        serde_json::to_vec(self)
    }

    /// Deserialize from JSON bytes
    pub fn from_bytes(bytes: &[u8]) -> Result<Self, serde_json::Error> {
        serde_json::from_slice(bytes)
    }
}

/// Configuration for usage tracking
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UsageConfig {
    /// Whether usage decay is enabled in ranking
    #[serde(default)]
    pub enabled: bool,

    /// Decay factor for usage penalty (higher = more aggressive)
    /// Formula: 1 / (1 + decay_factor * access_count)
    #[serde(default = "default_decay_factor")]
    pub decay_factor: f32,

    /// How often to flush pending writes (seconds)
    #[serde(default = "default_flush_interval")]
    pub flush_interval_secs: u64,

    /// How often to process prefetch queue (seconds)
    #[serde(default = "default_prefetch_interval")]
    pub prefetch_interval_secs: u64,

    /// LRU cache size (number of entries)
    #[serde(default = "default_cache_size")]
    pub cache_size: usize,
}

fn default_decay_factor() -> f32 { 0.15 }
fn default_flush_interval() -> u64 { 60 }
fn default_prefetch_interval() -> u64 { 5 }
fn default_cache_size() -> usize { 10_000 }

impl Default for UsageConfig {
    fn default() -> Self {
        Self {
            enabled: false,  // OFF by default until validated
            decay_factor: default_decay_factor(),
            flush_interval_secs: default_flush_interval(),
            prefetch_interval_secs: default_prefetch_interval(),
            cache_size: default_cache_size(),
        }
    }
}

/// Calculate usage penalty for ranking
/// Returns value between 0.0 and 1.0 (1.0 = no penalty)
pub fn usage_penalty(access_count: u32, decay_factor: f32) -> f32 {
    1.0 / (1.0 + decay_factor * access_count as f32)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_usage_stats_default() {
        let stats = UsageStats::new();
        assert_eq!(stats.access_count, 0);
        assert!(stats.last_accessed.is_none());
    }

    #[test]
    fn test_usage_stats_record_access() {
        let mut stats = UsageStats::new();
        stats.record_access();
        assert_eq!(stats.access_count, 1);
        assert!(stats.last_accessed.is_some());

        stats.record_access();
        assert_eq!(stats.access_count, 2);
    }

    #[test]
    fn test_usage_stats_serialization() {
        let mut stats = UsageStats::new();
        stats.record_access();

        let bytes = stats.to_bytes().unwrap();
        let decoded = UsageStats::from_bytes(&bytes).unwrap();

        assert_eq!(stats.access_count, decoded.access_count);
    }

    #[test]
    fn test_usage_penalty() {
        assert_eq!(usage_penalty(0, 0.15), 1.0);
        assert!(usage_penalty(1, 0.15) < 1.0);
        assert!(usage_penalty(10, 0.15) < usage_penalty(1, 0.15));
    }

    #[test]
    fn test_usage_config_default() {
        let config = UsageConfig::default();
        assert!(!config.enabled);
        assert_eq!(config.decay_factor, 0.15);
        assert_eq!(config.cache_size, 10_000);
    }
}
```

Export in `crates/memory-types/src/lib.rs`:
```rust
pub mod usage;
pub use usage::{UsageStats, UsageConfig, usage_penalty};
```

Add UsageConfig to RankingConfig in config.rs (if RankingConfig exists from 16-01):
```rust
#[serde(default)]
pub usage_decay: UsageConfig,
```
  </action>
  <verify>
```bash
cargo build -p memory-types
cargo test -p memory-types usage
```
  </verify>
  <done>UsageStats and UsageConfig exist in memory-types with serialization and tests</done>
</task>

<task type="auto">
  <name>Task 3: Create UsageTracker with cache-first reads and batched writes</name>
  <files>crates/memory-storage/src/usage.rs, crates/memory-storage/src/lib.rs</files>
  <action>
Create new file `crates/memory-storage/src/usage.rs`:

```rust
//! Usage tracking service with cache-first reads and batched writes.
//!
//! Key design principles (from Phase 16 Plan):
//! - Cache-first: get_usage_cached() NEVER blocks on CF read
//! - Batched writes: record_access() queues writes, flush() commits batch
//! - Async prefetch: cache misses queue prefetch, don't block current request
//! - Safe startup: if CF absent, created on first write; reads return defaults

use crate::column_families::CF_USAGE_COUNTERS;
use dashmap::DashMap;
use lru::LruCache;
use memory_types::usage::{UsageConfig, UsageStats};
use rocksdb::{WriteBatch, DB};
use std::num::NonZeroUsize;
use std::sync::{Arc, Mutex};
use tracing;

/// Pending write operation
struct UsageUpdate {
    stats: UsageStats,
}

/// Usage tracking service with cache-first design
pub struct UsageTracker {
    /// LRU cache for hot doc IDs (bounded)
    cache: Mutex<LruCache<String, UsageStats>>,
    /// Pending writes (batched)
    pending_writes: DashMap<String, UsageUpdate>,
    /// Pending prefetch requests
    prefetch_queue: DashMap<String, ()>,
    /// Database handle
    db: Arc<DB>,
    /// Configuration
    config: UsageConfig,
}

impl UsageTracker {
    /// Create new usage tracker
    ///
    /// Safe startup: CF_USAGE_COUNTERS is created on first write if absent.
    pub fn new(db: Arc<DB>, config: UsageConfig) -> Self {
        let cache_size = NonZeroUsize::new(config.cache_size.max(1))
            .expect("cache_size must be > 0");

        Self {
            cache: Mutex::new(LruCache::new(cache_size)),
            pending_writes: DashMap::new(),
            prefetch_queue: DashMap::new(),
            db,
            config,
        }
    }

    /// Record an access (batched write, non-blocking)
    ///
    /// Updates cache immediately, queues CF write for batch flush.
    pub fn record_access(&self, doc_id: &str) {
        // Update cache immediately
        {
            let mut cache = self.cache.lock().unwrap();
            let stats = cache.get_or_insert_mut(doc_id.to_string(), UsageStats::new);
            stats.record_access();
        }

        // Queue write for batch flush
        self.pending_writes.entry(doc_id.to_string())
            .and_modify(|update| update.stats.record_access())
            .or_insert_with(|| {
                let mut stats = UsageStats::new();
                stats.record_access();
                UsageUpdate { stats }
            });
    }

    /// Get usage for ranking - cache-first, NO blocking CF read
    ///
    /// Returns default UsageStats if not in cache.
    /// Queues prefetch for cache miss.
    pub fn get_usage_cached(&self, doc_id: &str) -> UsageStats {
        // Check cache first
        let cached = {
            let mut cache = self.cache.lock().unwrap();
            cache.get(doc_id).cloned()
        };

        if let Some(stats) = cached {
            return stats;
        }

        // Cache miss - queue prefetch (don't block)
        self.prefetch_queue.insert(doc_id.to_string(), ());

        // Return default (count=0)
        UsageStats::new()
    }

    /// Batch get for ranking - returns available data, queues prefetch for misses
    pub fn get_batch_cached(&self, doc_ids: &[String]) -> Vec<(String, UsageStats)> {
        let mut results = Vec::with_capacity(doc_ids.len());

        {
            let mut cache = self.cache.lock().unwrap();
            for doc_id in doc_ids {
                if let Some(stats) = cache.get(doc_id) {
                    results.push((doc_id.clone(), stats.clone()));
                } else {
                    // Queue prefetch
                    self.prefetch_queue.insert(doc_id.clone(), ());
                    results.push((doc_id.clone(), UsageStats::new()));
                }
            }
        }

        results
    }

    /// Flush pending writes (called by scheduler job)
    ///
    /// Returns number of writes flushed.
    pub fn flush_writes(&self) -> Result<u32, rocksdb::Error> {
        // Drain pending writes
        let writes: Vec<_> = self.pending_writes.iter()
            .map(|entry| (entry.key().clone(), entry.value().stats.clone()))
            .collect();

        if writes.is_empty() {
            return Ok(0);
        }

        // Get CF handle
        let cf = match self.db.cf_handle(CF_USAGE_COUNTERS) {
            Some(cf) => cf,
            None => {
                tracing::warn!("CF_USAGE_COUNTERS not found, skipping flush");
                return Ok(0);
            }
        };

        // Build batch
        let mut batch = WriteBatch::default();
        for (doc_id, stats) in &writes {
            let bytes = stats.to_bytes()
                .map_err(|e| rocksdb::Error::new(format!("serialize: {}", e)))?;
            batch.put_cf(&cf, doc_id.as_bytes(), &bytes);
        }

        // Commit batch
        self.db.write(batch)?;

        // Clear committed writes
        for (doc_id, _) in &writes {
            self.pending_writes.remove(doc_id);
        }

        let count = writes.len() as u32;
        tracing::info!(count, "Flushed usage writes to CF");
        Ok(count)
    }

    /// Process prefetch queue (called by scheduler job)
    ///
    /// Loads missing IDs from CF_USAGE_COUNTERS into cache.
    /// Returns number of entries prefetched.
    pub fn process_prefetch(&self) -> Result<u32, rocksdb::Error> {
        // Drain prefetch queue
        let to_fetch: Vec<String> = self.prefetch_queue.iter()
            .map(|entry| entry.key().clone())
            .collect();

        if to_fetch.is_empty() {
            return Ok(0);
        }

        // Get CF handle
        let cf = match self.db.cf_handle(CF_USAGE_COUNTERS) {
            Some(cf) => cf,
            None => {
                // CF doesn't exist yet, clear queue and return
                for doc_id in &to_fetch {
                    self.prefetch_queue.remove(doc_id);
                }
                return Ok(0);
            }
        };

        let mut prefetched = 0u32;

        for doc_id in &to_fetch {
            // Load from CF
            if let Some(bytes) = self.db.get_cf(&cf, doc_id.as_bytes())? {
                if let Ok(stats) = UsageStats::from_bytes(&bytes) {
                    // Populate cache
                    let mut cache = self.cache.lock().unwrap();
                    cache.put(doc_id.clone(), stats);
                    prefetched += 1;
                }
            }
            // Remove from queue regardless
            self.prefetch_queue.remove(doc_id);
        }

        if prefetched > 0 {
            tracing::debug!(prefetched, "Prefetched usage stats into cache");
        }

        Ok(prefetched)
    }

    /// Get cache statistics for metrics
    pub fn cache_stats(&self) -> (usize, usize) {
        let cache = self.cache.lock().unwrap();
        (cache.len(), cache.cap().get())
    }

    /// Get pending write count
    pub fn pending_write_count(&self) -> usize {
        self.pending_writes.len()
    }

    /// Get prefetch queue size
    pub fn prefetch_queue_size(&self) -> usize {
        self.prefetch_queue.len()
    }

    /// Get configuration
    pub fn config(&self) -> &UsageConfig {
        &self.config
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;
    use rocksdb::Options;

    fn create_test_db() -> (Arc<DB>, TempDir) {
        let tmp = TempDir::new().unwrap();
        let mut opts = Options::default();
        opts.create_if_missing(true);
        opts.create_missing_column_families(true);

        let cf_descs = crate::column_families::build_cf_descriptors();
        let db = DB::open_cf_descriptors(&opts, tmp.path(), cf_descs).unwrap();

        (Arc::new(db), tmp)
    }

    #[test]
    fn test_cache_first_returns_default_on_miss() {
        let (db, _tmp) = create_test_db();
        let tracker = UsageTracker::new(db, UsageConfig::default());

        let stats = tracker.get_usage_cached("unknown:doc:123");
        assert_eq!(stats.access_count, 0);
        assert!(stats.last_accessed.is_none());
    }

    #[test]
    fn test_record_access_updates_cache() {
        let (db, _tmp) = create_test_db();
        let tracker = UsageTracker::new(db, UsageConfig::default());

        tracker.record_access("doc:123");
        let stats = tracker.get_usage_cached("doc:123");
        assert_eq!(stats.access_count, 1);
        assert!(stats.last_accessed.is_some());
    }

    #[test]
    fn test_flush_writes_to_cf() {
        let (db, _tmp) = create_test_db();
        let tracker = UsageTracker::new(db.clone(), UsageConfig::default());

        tracker.record_access("doc:flush-test");
        let flushed = tracker.flush_writes().unwrap();
        assert_eq!(flushed, 1);
        assert_eq!(tracker.pending_write_count(), 0);

        // Verify written to CF
        let cf = db.cf_handle(CF_USAGE_COUNTERS).unwrap();
        let bytes = db.get_cf(&cf, b"doc:flush-test").unwrap().unwrap();
        let stats = UsageStats::from_bytes(&bytes).unwrap();
        assert_eq!(stats.access_count, 1);
    }

    #[test]
    fn test_prefetch_populates_cache() {
        let (db, _tmp) = create_test_db();

        // Write directly to CF
        let cf = db.cf_handle(CF_USAGE_COUNTERS).unwrap();
        let stats = UsageStats { access_count: 42, last_accessed: None };
        db.put_cf(&cf, b"doc:prefetch-test", stats.to_bytes().unwrap()).unwrap();

        let tracker = UsageTracker::new(db, UsageConfig::default());

        // First call returns default and queues prefetch
        let initial = tracker.get_usage_cached("doc:prefetch-test");
        assert_eq!(initial.access_count, 0);

        // Process prefetch
        let prefetched = tracker.process_prefetch().unwrap();
        assert_eq!(prefetched, 1);

        // Now cache should have the value
        let cached = tracker.get_usage_cached("doc:prefetch-test");
        assert_eq!(cached.access_count, 42);
    }
}
```

Export in `crates/memory-storage/src/lib.rs`:
```rust
pub mod usage;
pub use usage::UsageTracker;
```

Add to Cargo.toml for memory-storage:
```toml
[dependencies]
dashmap = "5"
lru = "0.12"
```
  </action>
  <verify>
```bash
cargo build -p memory-storage
cargo test -p memory-storage usage
```
  </verify>
  <done>UsageTracker exists with cache-first reads, batched writes, and prefetch; all tests pass</done>
</task>

</tasks>

<verification>
After all tasks complete:

```bash
# Full workspace build
cargo build --workspace

# All storage tests
cargo test -p memory-storage --all-features

# All types tests
cargo test -p memory-types --all-features

# Clippy check
cargo clippy -p memory-storage -p memory-types -- -D warnings
```
</verification>

<success_criteria>
1. CF_USAGE_COUNTERS constant exists in column_families.rs
2. UsageStats and UsageConfig types exist in memory-types
3. UsageTracker exists in memory-storage with cache-first design
4. record_access() updates cache immediately and queues write
5. get_usage_cached() returns cached data or default (never blocks on CF)
6. flush_writes() batches pending writes to CF
7. process_prefetch() loads missed IDs from CF into cache
8. All tests pass including cache-miss, flush, and prefetch tests
9. Clippy passes with no warnings
</success_criteria>

<output>
After completion, create `.planning/phases/16-memory-ranking-enhancements/16-02-SUMMARY.md`
</output>
