---
phase: 14-topic-graph-memory
plan: 06
type: execute
wave: 6
depends_on: ["14-05"]
files_modified:
  - crates/memory-topics/src/lifecycle.rs
  - crates/memory-topics/src/jobs.rs
  - crates/memory-topics/src/lib.rs
  - crates/memory-daemon/src/main.rs
  - crates/memory-cli/src/commands/topic.rs
autonomous: true

must_haves:
  truths:
    - "Inactive topics are pruned after configurable days of inactivity"
    - "Pruned topics can be resurrected when re-mentioned"
    - "Topic extraction job runs on configurable schedule"
    - "Pruning job runs weekly by default"
    - "CLI provides topic list, show, and stats commands"
  artifacts:
    - path: "crates/memory-topics/src/lifecycle.rs"
      provides: "Topic pruning and resurrection logic"
      exports: ["prune_inactive_topics", "resurrect_topic", "LifecycleManager"]
    - path: "crates/memory-topics/src/jobs.rs"
      provides: "Scheduler job integration"
      exports: ["create_topic_extraction_job", "create_topic_pruning_job"]
    - path: "crates/memory-cli/src/commands/topic.rs"
      provides: "CLI commands for topic operations"
      exports: ["TopicCommand"]
  key_links:
    - from: "crates/memory-topics/src/jobs.rs"
      to: "memory-scheduler"
      via: "registers jobs with scheduler"
      pattern: "register_job"
    - from: "crates/memory-topics/src/lifecycle.rs"
      to: "crates/memory-topics/src/storage.rs"
      via: "updates topic status"
      pattern: "save_topic"
---

<objective>
Implement topic lifecycle management: pruning, resurrection, scheduled jobs, and CLI.

Purpose: Keep the topic graph healthy by removing stale topics and allowing them to return when relevant again. Scheduled jobs automate extraction and pruning. CLI enables manual topic exploration and debugging.

Output: LifecycleManager with pruning/resurrection, scheduler jobs for extraction and pruning, CLI topic commands.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/14-topic-graph-memory/14-RESEARCH.md
@.planning/phases/14-topic-graph-memory/14-05-SUMMARY.md
@crates/memory-scheduler/src/lib.rs
@crates/memory-cli/src/main.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement lifecycle management (pruning and resurrection)</name>
  <files>
    crates/memory-topics/src/lifecycle.rs
    crates/memory-topics/src/lib.rs
  </files>
  <action>
Create lifecycle management module:

1. Create `crates/memory-topics/src/lifecycle.rs`:
   ```rust
   //! Topic lifecycle management.
   //!
   //! Handles pruning of inactive topics and resurrection when re-mentioned.

   use chrono::{DateTime, Duration, Utc};
   use tracing::{debug, info, warn};

   use crate::config::LifecycleConfig;
   use crate::error::TopicsError;
   use crate::storage::TopicStorage;
   use crate::types::{Topic, TopicStatus};

   /// Lifecycle manager for topics.
   pub struct LifecycleManager {
       config: LifecycleConfig,
   }

   impl LifecycleManager {
       /// Create a new lifecycle manager.
       pub fn new(config: LifecycleConfig) -> Self {
           Self { config }
       }

       /// Get configuration.
       pub fn config(&self) -> &LifecycleConfig {
           &self.config
       }

       /// Prune topics that have been inactive for too long.
       ///
       /// Returns the number of topics pruned.
       pub fn prune_inactive(
           &self,
           storage: &TopicStorage,
           now: DateTime<Utc>,
       ) -> Result<usize, TopicsError> {
           let cutoff = now - Duration::days(self.config.prune_after_days as i64);
           let topics = storage.list_topics()?;

           info!(
               total = topics.len(),
               cutoff = %cutoff,
               "Checking for inactive topics to prune"
           );

           let mut pruned_count = 0;

           for topic in topics {
               if should_prune(&topic, cutoff) {
                   debug!(
                       topic_id = %topic.topic_id,
                       last_mentioned = %topic.last_mentioned_at,
                       "Pruning inactive topic"
                   );

                   let mut pruned_topic = topic;
                   pruned_topic.status = TopicStatus::Pruned;
                   storage.save_topic(&pruned_topic)?;
                   pruned_count += 1;
               }
           }

           info!(pruned = pruned_count, "Pruning complete");
           Ok(pruned_count)
       }

       /// Resurrect a pruned topic.
       ///
       /// Called when a pruned topic is mentioned again.
       pub fn resurrect_topic(
           &self,
           storage: &TopicStorage,
           topic_id: &str,
           new_mention_time: DateTime<Utc>,
       ) -> Result<bool, TopicsError> {
           if !self.config.auto_resurrect {
               debug!(topic_id = %topic_id, "Auto-resurrection disabled");
               return Ok(false);
           }

           let topic = storage.get_topic(topic_id)?;

           match topic {
               Some(mut t) if t.status == TopicStatus::Pruned => {
                   info!(topic_id = %topic_id, "Resurrecting pruned topic");
                   t.status = TopicStatus::Active;
                   t.last_mentioned_at = new_mention_time;
                   storage.save_topic(&t)?;
                   Ok(true)
               }
               Some(_) => {
                   debug!(topic_id = %topic_id, "Topic is already active");
                   Ok(false)
               }
               None => {
                   warn!(topic_id = %topic_id, "Topic not found for resurrection");
                   Ok(false)
               }
           }
       }

       /// Update last_mentioned_at for a topic, resurrecting if needed.
       pub fn touch_topic(
           &self,
           storage: &TopicStorage,
           topic_id: &str,
           mention_time: DateTime<Utc>,
       ) -> Result<(), TopicsError> {
           let topic = storage.get_topic(topic_id)?;

           match topic {
               Some(mut t) => {
                   // Resurrect if pruned
                   if t.status == TopicStatus::Pruned && self.config.auto_resurrect {
                       info!(topic_id = %topic_id, "Resurrecting on touch");
                       t.status = TopicStatus::Active;
                   }

                   // Update timestamp
                   t.last_mentioned_at = mention_time;
                   storage.save_topic(&t)?;
                   Ok(())
               }
               None => {
                   debug!(topic_id = %topic_id, "Topic not found for touch");
                   Ok(())
               }
           }
       }

       /// Get count of active vs pruned topics.
       pub fn get_lifecycle_stats(
           &self,
           storage: &TopicStorage,
       ) -> Result<LifecycleStats, TopicsError> {
           let topics = storage
               .storage()
               .prefix_iterator(crate::storage::CF_TOPICS, b"topic:")
               .map_err(TopicsError::Storage)?;

           let mut active = 0u64;
           let mut pruned = 0u64;

           for (_, value) in topics {
               let topic: Topic = serde_json::from_slice(&value)?;
               match topic.status {
                   TopicStatus::Active => active += 1,
                   TopicStatus::Pruned => pruned += 1,
               }
           }

           Ok(LifecycleStats { active, pruned })
       }
   }

   /// Lifecycle statistics.
   #[derive(Debug, Clone, Default)]
   pub struct LifecycleStats {
       pub active: u64,
       pub pruned: u64,
   }

   impl LifecycleStats {
       pub fn total(&self) -> u64 {
           self.active + self.pruned
       }
   }

   /// Determine if a topic should be pruned.
   fn should_prune(topic: &Topic, cutoff: DateTime<Utc>) -> bool {
       // Only prune active topics
       topic.status == TopicStatus::Active && topic.last_mentioned_at < cutoff
   }

   /// Prune inactive topics (standalone function for job use).
   pub fn prune_inactive_topics(
       storage: &TopicStorage,
       config: &LifecycleConfig,
   ) -> Result<usize, TopicsError> {
       let manager = LifecycleManager::new(config.clone());
       manager.prune_inactive(storage, Utc::now())
   }

   /// Resurrect a topic (standalone function).
   pub fn resurrect_topic(
       storage: &TopicStorage,
       config: &LifecycleConfig,
       topic_id: &str,
   ) -> Result<bool, TopicsError> {
       let manager = LifecycleManager::new(config.clone());
       manager.resurrect_topic(storage, topic_id, Utc::now())
   }

   #[cfg(test)]
   mod tests {
       use super::*;

       fn default_config() -> LifecycleConfig {
           LifecycleConfig {
               prune_after_days: 90,
               prune_schedule: "0 5 * * 0".to_string(),
               auto_resurrect: true,
           }
       }

       fn make_topic(id: &str, last_mentioned: DateTime<Utc>, status: TopicStatus) -> Topic {
           Topic {
               topic_id: id.to_string(),
               label: format!("Topic {}", id),
               embedding: vec![0.1, 0.2],
               importance_score: 1.0,
               node_count: 1,
               created_at: last_mentioned - Duration::days(100),
               last_mentioned_at: last_mentioned,
               status,
               keywords: vec![],
           }
       }

       #[test]
       fn test_should_prune_inactive() {
           let now = Utc::now();
           let cutoff = now - Duration::days(90);

           // 100 days ago - should prune
           let old_topic = make_topic("old", now - Duration::days(100), TopicStatus::Active);
           assert!(should_prune(&old_topic, cutoff));

           // 10 days ago - should not prune
           let recent_topic = make_topic("recent", now - Duration::days(10), TopicStatus::Active);
           assert!(!should_prune(&recent_topic, cutoff));
       }

       #[test]
       fn test_should_not_prune_already_pruned() {
           let now = Utc::now();
           let cutoff = now - Duration::days(90);

           // Already pruned - don't prune again
           let pruned_topic = make_topic("pruned", now - Duration::days(100), TopicStatus::Pruned);
           assert!(!should_prune(&pruned_topic, cutoff));
       }

       #[test]
       fn test_lifecycle_stats() {
           let stats = LifecycleStats {
               active: 10,
               pruned: 5,
           };
           assert_eq!(stats.total(), 15);
       }
   }
   ```

2. Update `crates/memory-topics/src/lib.rs` to export lifecycle module:
   ```rust
   // Add to existing exports:
   pub mod lifecycle;
   pub use lifecycle::{prune_inactive_topics, resurrect_topic, LifecycleManager, LifecycleStats};
   ```
  </action>
  <verify>
    cd /Users/richardhightower/clients/spillwave/src/agent-memory && cargo test -p memory-topics lifecycle
  </verify>
  <done>
    LifecycleManager with pruning and resurrection. Auto-resurrect on re-mention. LifecycleStats for monitoring. All tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement scheduler job integration</name>
  <files>
    crates/memory-topics/src/jobs.rs
    crates/memory-topics/src/lib.rs
  </files>
  <action>
Create scheduler job integration:

1. Create `crates/memory-topics/src/jobs.rs`:
   ```rust
   //! Scheduler job integration for topics.
   //!
   //! Registers topic extraction and pruning jobs with the scheduler.

   use std::sync::Arc;

   use memory_scheduler::{JitterConfig, OverlapPolicy, SchedulerService};
   use memory_storage::Storage;
   use tracing::{error, info};

   use crate::config::TopicsConfig;
   use crate::error::TopicsError;
   use crate::extraction::TopicExtractor;
   use crate::importance::ImportanceCalculator;
   use crate::lifecycle::LifecycleManager;
   use crate::storage::TopicStorage;

   /// Job name for topic extraction
   pub const EXTRACTION_JOB_NAME: &str = "topic-extraction";

   /// Job name for topic pruning
   pub const PRUNING_JOB_NAME: &str = "topic-pruning";

   /// Register topic jobs with the scheduler.
   ///
   /// # Arguments
   /// * `scheduler` - The scheduler service
   /// * `storage` - The underlying RocksDB storage
   /// * `config` - Topic configuration
   ///
   /// # Returns
   /// Number of jobs registered (0, 1, or 2)
   pub async fn register_topic_jobs(
       scheduler: &SchedulerService,
       storage: Arc<Storage>,
       config: &TopicsConfig,
   ) -> Result<usize, TopicsError> {
       if !config.enabled {
           info!("Topics disabled, skipping job registration");
           return Ok(0);
       }

       let mut registered = 0;

       // Register extraction job
       match register_extraction_job(scheduler, storage.clone(), config).await {
           Ok(_) => {
               registered += 1;
               info!(job = EXTRACTION_JOB_NAME, "Registered extraction job");
           }
           Err(e) => {
               error!(error = %e, "Failed to register extraction job");
           }
       }

       // Register pruning job
       match register_pruning_job(scheduler, storage, config).await {
           Ok(_) => {
               registered += 1;
               info!(job = PRUNING_JOB_NAME, "Registered pruning job");
           }
           Err(e) => {
               error!(error = %e, "Failed to register pruning job");
           }
       }

       Ok(registered)
   }

   /// Register the topic extraction job.
   async fn register_extraction_job(
       scheduler: &SchedulerService,
       storage: Arc<Storage>,
       config: &TopicsConfig,
   ) -> Result<(), TopicsError> {
       let topic_storage = Arc::new(TopicStorage::new(storage.clone()));
       let extractor = Arc::new(TopicExtractor::new(config.extraction.clone()));
       let importance_calc = Arc::new(ImportanceCalculator::new(config.importance.clone()));

       let schedule = config.extraction.schedule.clone();

       scheduler
           .register_job(
               EXTRACTION_JOB_NAME,
               &schedule,
               None, // Use default timezone
               OverlapPolicy::Skip,
               JitterConfig::new(300), // Up to 5 minutes jitter
               move |_cancel| {
                   let storage = topic_storage.clone();
                   let extractor = extractor.clone();
                   let calc = importance_calc.clone();

                   async move {
                       info!("Starting topic extraction job");

                       // Note: Full extraction requires Phase 12 embeddings
                       // For now, just recalculate importance scores
                       match calc.recalculate_all(&storage).await {
                           Ok(updated) => {
                               info!(updated = updated, "Extraction job complete");
                               Ok(())
                           }
                           Err(e) => {
                               error!(error = %e, "Extraction job failed");
                               Err(e.to_string())
                           }
                       }
                   }
               },
           )
           .await
           .map_err(|e| TopicsError::InvalidConfig(e.to_string()))
   }

   /// Register the topic pruning job.
   async fn register_pruning_job(
       scheduler: &SchedulerService,
       storage: Arc<Storage>,
       config: &TopicsConfig,
   ) -> Result<(), TopicsError> {
       let topic_storage = Arc::new(TopicStorage::new(storage));
       let lifecycle_config = config.lifecycle.clone();

       let schedule = config.lifecycle.prune_schedule.clone();

       scheduler
           .register_job(
               PRUNING_JOB_NAME,
               &schedule,
               None,
               OverlapPolicy::Skip,
               JitterConfig::new(60), // Up to 1 minute jitter
               move |_cancel| {
                   let storage = topic_storage.clone();
                   let config = lifecycle_config.clone();

                   async move {
                       info!("Starting topic pruning job");

                       let manager = LifecycleManager::new(config);
                       match manager.prune_inactive(&storage, chrono::Utc::now()) {
                           Ok(pruned) => {
                               info!(pruned = pruned, "Pruning job complete");
                               Ok(())
                           }
                           Err(e) => {
                               error!(error = %e, "Pruning job failed");
                               Err(e.to_string())
                           }
                       }
                   }
               },
           )
           .await
           .map_err(|e| TopicsError::InvalidConfig(e.to_string()))
   }

   /// Create topic extraction job manually (for testing or one-off runs).
   pub async fn run_extraction_once(
       storage: Arc<Storage>,
       config: &TopicsConfig,
   ) -> Result<usize, TopicsError> {
       let topic_storage = TopicStorage::new(storage);
       let calc = ImportanceCalculator::new(config.importance.clone());

       calc.recalculate_all(&topic_storage).await
   }

   /// Create pruning job manually.
   pub async fn run_pruning_once(
       storage: Arc<Storage>,
       config: &TopicsConfig,
   ) -> Result<usize, TopicsError> {
       let topic_storage = TopicStorage::new(storage);
       let manager = LifecycleManager::new(config.lifecycle.clone());

       manager.prune_inactive(&topic_storage, chrono::Utc::now())
   }

   #[cfg(test)]
   mod tests {
       use super::*;

       #[test]
       fn test_job_names() {
           assert_eq!(EXTRACTION_JOB_NAME, "topic-extraction");
           assert_eq!(PRUNING_JOB_NAME, "topic-pruning");
       }
   }
   ```

2. Update `crates/memory-topics/src/lib.rs` to export jobs module:
   ```rust
   // Add to existing exports:
   pub mod jobs;
   pub use jobs::{register_topic_jobs, run_extraction_once, run_pruning_once, EXTRACTION_JOB_NAME, PRUNING_JOB_NAME};
   ```

3. Add memory-scheduler dependency to `crates/memory-topics/Cargo.toml`:
   ```toml
   # Add to [dependencies]
   memory-scheduler = { workspace = true, optional = true }

   # Add to [features]
   scheduler = ["dep:memory-scheduler"]
   ```
  </action>
  <verify>
    cd /Users/richardhightower/clients/spillwave/src/agent-memory && cargo build -p memory-topics --features scheduler
  </verify>
  <done>
    Scheduler job integration with extraction and pruning jobs. Feature-gated behind "scheduler". Manual run functions for testing.
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement CLI topic commands</name>
  <files>
    crates/memory-cli/src/commands/topic.rs
    crates/memory-cli/src/main.rs
  </files>
  <action>
Create CLI commands for topic operations:

1. Create `crates/memory-cli/src/commands/topic.rs`:
   ```rust
   //! CLI commands for topic operations.

   use clap::{Args, Subcommand};
   use tonic::transport::Channel;
   use tracing::info;

   use crate::proto::memory_client::MemoryClient;
   use crate::proto::{
       GetRelatedTopicsRequest, GetTopTopicsRequest, GetTopicGraphStatusRequest,
       GetTopicsByQueryRequest, TopicRelationshipType,
   };

   /// Topic-related commands
   #[derive(Debug, Args)]
   pub struct TopicCommand {
       #[command(subcommand)]
       pub command: TopicSubcommand,
   }

   #[derive(Debug, Subcommand)]
   pub enum TopicSubcommand {
       /// Show topic graph status
       Status,

       /// List top topics by importance
       List {
           /// Number of topics to show
           #[arg(short, long, default_value = "10")]
           limit: u32,
       },

       /// Search for topics by query
       Search {
           /// Search query
           query: String,

           /// Number of results
           #[arg(short, long, default_value = "10")]
           limit: u32,
       },

       /// Show details for a specific topic
       Show {
           /// Topic ID
           topic_id: String,
       },

       /// Show related topics
       Related {
           /// Topic ID
           topic_id: String,

           /// Relationship types (similar, parent, child)
           #[arg(short, long, value_delimiter = ',', default_value = "similar")]
           types: Vec<String>,

           /// Number of results
           #[arg(short, long, default_value = "10")]
           limit: u32,
       },
   }

   impl TopicCommand {
       /// Execute the topic command
       pub async fn execute(&self, client: &mut MemoryClient<Channel>) -> anyhow::Result<()> {
           match &self.command {
               TopicSubcommand::Status => execute_status(client).await,
               TopicSubcommand::List { limit } => execute_list(client, *limit).await,
               TopicSubcommand::Search { query, limit } => {
                   execute_search(client, query, *limit).await
               }
               TopicSubcommand::Show { topic_id } => execute_show(client, topic_id).await,
               TopicSubcommand::Related {
                   topic_id,
                   types,
                   limit,
               } => execute_related(client, topic_id, types, *limit).await,
           }
       }
   }

   async fn execute_status(client: &mut MemoryClient<Channel>) -> anyhow::Result<()> {
       let response = client
           .get_topic_graph_status(GetTopicGraphStatusRequest {})
           .await?
           .into_inner();

       println!("Topic Graph Status");
       println!("==================");
       println!("Enabled:      {}", response.enabled);
       println!("Healthy:      {}", response.healthy);
       println!("Topic Count:  {}", response.topic_count);
       println!("Link Count:   {}", response.link_count);
       println!("Message:      {}", response.message);
       println!();
       println!("Configuration:");
       println!("  Half-life:  {} days", response.half_life_days);
       println!("  Similarity: {:.2}", response.similarity_threshold);

       if response.last_extraction_ms > 0 {
           let dt = chrono::DateTime::from_timestamp_millis(response.last_extraction_ms)
               .map(|d| d.format("%Y-%m-%d %H:%M:%S").to_string())
               .unwrap_or_else(|| "unknown".to_string());
           println!("  Last Run:   {}", dt);
       }

       Ok(())
   }

   async fn execute_list(client: &mut MemoryClient<Channel>, limit: u32) -> anyhow::Result<()> {
       let response = client
           .get_top_topics(GetTopTopicsRequest {
               limit: limit as i32,
               start_time_ms: 0,
               end_time_ms: 0,
           })
           .await?
           .into_inner();

       if response.topics.is_empty() {
           println!("No topics found.");
           return Ok(());
       }

       println!("Top {} Topics by Importance", response.topics.len());
       println!("{:-<60}", "");
       println!(
           "{:<30} {:>10} {:>10} {:>8}",
           "Label", "Importance", "Nodes", "Keywords"
       );
       println!("{:-<60}", "");

       for topic in &response.topics {
           println!(
               "{:<30} {:>10.3} {:>10} {:>8}",
               truncate(&topic.label, 30),
               topic.importance_score,
               topic.node_count,
               topic.keywords.len()
           );
       }

       Ok(())
   }

   async fn execute_search(
       client: &mut MemoryClient<Channel>,
       query: &str,
       limit: u32,
   ) -> anyhow::Result<()> {
       let response = client
           .get_topics_by_query(GetTopicsByQueryRequest {
               query: query.to_string(),
               limit: limit as i32,
               min_score: 0.0,
           })
           .await?
           .into_inner();

       if response.topics.is_empty() {
           println!("No topics match '{}'", query);
           return Ok(());
       }

       println!("Topics matching '{}':", query);
       println!("{:-<60}", "");
       println!("{:<30} {:>10} {:>10}", "Label", "Score", "Importance");
       println!("{:-<60}", "");

       for (topic, score) in response.topics.iter().zip(response.scores.iter()) {
           println!(
               "{:<30} {:>10.3} {:>10.3}",
               truncate(&topic.label, 30),
               score,
               topic.importance_score
           );
       }

       Ok(())
   }

   async fn execute_show(
       client: &mut MemoryClient<Channel>,
       topic_id: &str,
   ) -> anyhow::Result<()> {
       // Get topic details via search (single result)
       let response = client
           .get_topics_by_query(GetTopicsByQueryRequest {
               query: topic_id.to_string(),
               limit: 1,
               min_score: 0.0,
           })
           .await?
           .into_inner();

       if response.topics.is_empty() {
           println!("Topic not found: {}", topic_id);
           return Ok(());
       }

       let topic = &response.topics[0];

       println!("Topic Details");
       println!("=============");
       println!("ID:           {}", topic.topic_id);
       println!("Label:        {}", topic.label);
       println!("Importance:   {:.3}", topic.importance_score);
       println!("Node Count:   {}", topic.node_count);
       println!(
           "Keywords:     {}",
           if topic.keywords.is_empty() {
               "(none)".to_string()
           } else {
               topic.keywords.join(", ")
           }
       );

       if topic.created_at_ms > 0 {
           let created = chrono::DateTime::from_timestamp_millis(topic.created_at_ms)
               .map(|d| d.format("%Y-%m-%d %H:%M").to_string())
               .unwrap_or_else(|| "unknown".to_string());
           println!("Created:      {}", created);
       }

       if topic.last_mentioned_at_ms > 0 {
           let mentioned = chrono::DateTime::from_timestamp_millis(topic.last_mentioned_at_ms)
               .map(|d| d.format("%Y-%m-%d %H:%M").to_string())
               .unwrap_or_else(|| "unknown".to_string());
           println!("Last Active:  {}", mentioned);
       }

       Ok(())
   }

   async fn execute_related(
       client: &mut MemoryClient<Channel>,
       topic_id: &str,
       types: &[String],
       limit: u32,
   ) -> anyhow::Result<()> {
       // Parse relationship types
       let rel_types: Vec<i32> = types
           .iter()
           .filter_map(|t| match t.to_lowercase().as_str() {
               "similar" | "sim" => Some(TopicRelationshipType::Similar as i32),
               "parent" | "par" => Some(TopicRelationshipType::Parent as i32),
               "child" | "chi" => Some(TopicRelationshipType::Child as i32),
               _ => None,
           })
           .collect();

       if rel_types.is_empty() {
           println!("Invalid relationship types. Use: similar, parent, child");
           return Ok(());
       }

       let response = client
           .get_related_topics(GetRelatedTopicsRequest {
               topic_id: topic_id.to_string(),
               relationship_types: rel_types,
               limit: limit as i32,
           })
           .await?
           .into_inner();

       if response.related.is_empty() {
           println!("No related topics found for {}", topic_id);
           return Ok(());
       }

       println!("Related Topics for {}", topic_id);
       println!("{:-<70}", "");
       println!(
           "{:<30} {:>12} {:>10} {:>10}",
           "Label", "Relationship", "Score", "Importance"
       );
       println!("{:-<70}", "");

       for rel in &response.related {
           if let Some(topic) = &rel.topic {
               let rel_type = match rel.relationship_type {
                   1 => "Similar",
                   2 => "Parent",
                   3 => "Child",
                   _ => "Unknown",
               };

               println!(
                   "{:<30} {:>12} {:>10.3} {:>10.3}",
                   truncate(&topic.label, 30),
                   rel_type,
                   rel.score,
                   topic.importance_score
               );
           }
       }

       Ok(())
   }

   fn truncate(s: &str, max_len: usize) -> String {
       if s.len() <= max_len {
           s.to_string()
       } else {
           format!("{}...", &s[..max_len - 3])
       }
   }
   ```

2. Update `crates/memory-cli/src/main.rs` to add topic command:
   ```rust
   // Add to imports:
   mod commands;
   use commands::topic::TopicCommand;

   // Add to CLI enum:
   #[derive(Debug, Subcommand)]
   enum Commands {
       // ... existing commands ...

       /// Topic graph commands
       Topic(TopicCommand),
   }

   // Add to match in execute:
   Commands::Topic(cmd) => cmd.execute(&mut client).await?,
   ```
  </action>
  <verify>
    cd /Users/richardhightower/clients/spillwave/src/agent-memory && cargo build -p memory-cli
  </verify>
  <done>
    CLI topic commands: status, list, search, show, related. Integration with gRPC client. Formatted output.
  </done>
</task>

</tasks>

<verification>
```bash
cd /Users/richardhightower/clients/spillwave/src/agent-memory

# All components compile
cargo build -p memory-topics --features scheduler
cargo build -p memory-cli

# Tests pass
cargo test -p memory-topics lifecycle
cargo test -p memory-topics jobs

# Clippy clean
cargo clippy -p memory-topics --features scheduler -- -D warnings
cargo clippy -p memory-cli -- -D warnings

# CLI help works
cargo run -p memory-cli -- topic --help
```
</verification>

<success_criteria>
- [ ] LifecycleManager implements pruning based on inactivity
- [ ] Auto-resurrection restores pruned topics on re-mention
- [ ] touch_topic updates last_mentioned_at
- [ ] register_topic_jobs integrates with scheduler
- [ ] Extraction job recalculates importance scores
- [ ] Pruning job removes inactive topics
- [ ] CLI topic status shows graph health
- [ ] CLI topic list shows top topics
- [ ] CLI topic search finds by query
- [ ] CLI topic show displays details
- [ ] CLI topic related shows relationships
- [ ] All tests pass
- [ ] No clippy warnings
</success_criteria>

<output>
After completion, create `.planning/phases/14-topic-graph-memory/14-06-SUMMARY.md`
</output>
