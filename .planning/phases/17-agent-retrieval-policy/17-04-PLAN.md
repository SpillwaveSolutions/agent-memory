---
phase: 17-agent-retrieval-policy
plan: 04
type: execute
wave: 3
depends_on: ["17-01", "17-02", "17-03"]
files_modified:
  - crates/memory-retrieval/src/executor.rs
  - crates/memory-retrieval/src/fallback.rs
  - crates/memory-retrieval/src/lib.rs
autonomous: true

must_haves:
  truths:
    - "FallbackChain executes layers in order, skipping disabled ones"
    - "Execution respects stop conditions (timeout, max_nodes, max_rpc_calls)"
    - "Parallel execution uses bounded fan-out (beam_width 2-5)"
    - "Early stopping cancels other paths when strong evidence found"
    - "Agentic fallback always available (never hard-fail)"
  artifacts:
    - path: "crates/memory-retrieval/src/executor.rs"
      provides: "Retrieval execution engine"
      exports: ["RetrievalExecutor", "ExecutionResult", "LayerResult"]
    - path: "crates/memory-retrieval/src/fallback.rs"
      provides: "Fallback chain implementation"
      exports: ["FallbackChain", "FallbackStep"]
  key_links:
    - from: "crates/memory-retrieval/src/lib.rs"
      to: "crates/memory-retrieval/src/executor.rs"
      via: "pub mod executor"
      pattern: "pub mod executor"
    - from: "crates/memory-retrieval/src/executor.rs"
      to: "crates/memory-retrieval/src/fallback.rs"
      via: "use crate::fallback"
      pattern: "use crate::fallback"
---

<objective>
Implement the retrieval execution engine with fallback chains and parallel execution.

Purpose: Per PRD Sections 4 and 5.4, the execution engine runs layers in order with automatic fallback on failure. FR-07 requires configuration-aware search, FR-08 requires graceful degradation, FR-09 requires partial result return on timeout. FR-15-18 cover execution modes (Sequential/Parallel/Hybrid) with bounded fan-out and rank fusion.

Output: RetrievalExecutor that orchestrates layer execution with stop condition enforcement, fallback chains, and parallel execution support.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/17-agent-retrieval-policy/17-01-SUMMARY.md
@.planning/phases/17-agent-retrieval-policy/17-02-SUMMARY.md
@.planning/phases/17-agent-retrieval-policy/17-03-SUMMARY.md

# Technical reference
@docs/prds/agent-retrieval-policy-prd.md
@crates/memory-service/src/hybrid.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create fallback chain implementation</name>
  <files>crates/memory-retrieval/src/fallback.rs</files>
  <action>
Create `crates/memory-retrieval/src/fallback.rs`:

```rust
//! Fallback chain implementation.
//!
//! Implements FR-07 (configuration-aware search) and FR-08 (graceful degradation).
//!
//! Chains execute layers in order, skipping disabled ones, with automatic
//! fallback on failure. Agentic TOC search is always the final fallback.

use memory_types::retrieval::{CapabilityTier, ExecutionMode, QueryIntent, StopConditions};
use serde::{Deserialize, Serialize};
use std::time::{Duration, Instant};
use tracing::{debug, info, warn};

/// Result from executing a single layer.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LayerResult {
    /// Layer name that produced this result
    pub layer: String,
    /// Whether the layer execution succeeded
    pub success: bool,
    /// Number of results found
    pub result_count: usize,
    /// Execution time in milliseconds
    pub duration_ms: u64,
    /// Error message if failed
    pub error: Option<String>,
    /// Whether this was a fallback from a prior layer
    pub is_fallback: bool,
    /// Score/confidence of results (0.0-1.0)
    pub confidence: f32,
}

impl LayerResult {
    /// Create a successful result.
    pub fn success(layer: &str, result_count: usize, duration_ms: u64, confidence: f32) -> Self {
        Self {
            layer: layer.to_string(),
            success: true,
            result_count,
            duration_ms,
            error: None,
            is_fallback: false,
            confidence,
        }
    }

    /// Create a failed result.
    pub fn failure(layer: &str, error: &str, duration_ms: u64) -> Self {
        Self {
            layer: layer.to_string(),
            success: false,
            result_count: 0,
            duration_ms,
            error: Some(error.to_string()),
            is_fallback: false,
            confidence: 0.0,
        }
    }

    /// Mark as fallback result.
    pub fn as_fallback(mut self) -> Self {
        self.is_fallback = true;
        self
    }

    /// Check if results are sufficient (non-zero count with decent confidence).
    pub fn is_sufficient(&self) -> bool {
        self.success && self.result_count > 0 && self.confidence > 0.3
    }
}

/// A step in the fallback chain.
#[derive(Debug, Clone)]
pub struct FallbackStep {
    /// Layer name
    pub layer: String,
    /// Whether this layer is enabled
    pub enabled: bool,
    /// Whether this layer is healthy
    pub healthy: bool,
    /// Priority order (lower = higher priority)
    pub priority: u32,
}

impl FallbackStep {
    /// Check if this step can be executed.
    pub fn can_execute(&self) -> bool {
        self.enabled && self.healthy
    }
}

/// Fallback chain that executes layers in order with automatic degradation.
#[derive(Debug, Clone)]
pub struct FallbackChain {
    /// Ordered steps in the chain
    steps: Vec<FallbackStep>,
    /// Stop conditions
    stop_conditions: StopConditions,
    /// Current RPC call count
    rpc_calls: u32,
    /// Current node visit count
    nodes_visited: u32,
    /// Start time for timeout tracking
    start_time: Option<Instant>,
}

impl FallbackChain {
    /// Create a new fallback chain from steps.
    pub fn new(steps: Vec<FallbackStep>, stop_conditions: StopConditions) -> Self {
        Self {
            steps,
            stop_conditions,
            rpc_calls: 0,
            nodes_visited: 0,
            start_time: None,
        }
    }

    /// Create a chain from tier and intent.
    pub fn from_route(
        route: &crate::tier::RouteSelection,
        status: &crate::tier::CombinedStatus,
        stop_conditions: StopConditions,
    ) -> Self {
        let mut steps = Vec::new();
        let mut priority = 0;

        // Add primary layer
        steps.push(FallbackStep {
            layer: route.primary.to_string(),
            enabled: Self::layer_enabled(route.primary, status),
            healthy: Self::layer_healthy(route.primary, status),
            priority,
        });

        // Add fallback layers
        for layer in &route.fallbacks {
            priority += 1;
            steps.push(FallbackStep {
                layer: layer.to_string(),
                enabled: Self::layer_enabled(layer, status),
                healthy: Self::layer_healthy(layer, status),
                priority,
            });
        }

        Self::new(steps, stop_conditions)
    }

    /// Check if a layer is enabled based on status.
    fn layer_enabled(layer: &str, status: &crate::tier::CombinedStatus) -> bool {
        match layer {
            "bm25" => status.bm25.enabled,
            "vector" => status.vector.enabled,
            "topics" => status.topics.enabled,
            "hybrid" => status.bm25.enabled && status.vector.enabled,
            "agentic" => true, // Always enabled
            _ => false,
        }
    }

    /// Check if a layer is healthy based on status.
    fn layer_healthy(layer: &str, status: &crate::tier::CombinedStatus) -> bool {
        match layer {
            "bm25" => status.bm25.healthy,
            "vector" => status.vector.healthy,
            "topics" => status.topics.healthy,
            "hybrid" => status.bm25.healthy && status.vector.healthy,
            "agentic" => true, // Always healthy
            _ => false,
        }
    }

    /// Start execution timing.
    pub fn start(&mut self) {
        self.start_time = Some(Instant::now());
        self.rpc_calls = 0;
        self.nodes_visited = 0;
    }

    /// Get next executable step, or None if chain exhausted.
    pub fn next_step(&self) -> Option<&FallbackStep> {
        self.steps.iter().find(|s| s.can_execute())
    }

    /// Get all executable steps in order.
    pub fn executable_steps(&self) -> Vec<&FallbackStep> {
        self.steps.iter().filter(|s| s.can_execute()).collect()
    }

    /// Record an RPC call.
    pub fn record_rpc(&mut self) {
        self.rpc_calls += 1;
    }

    /// Record nodes visited.
    pub fn record_nodes(&mut self, count: u32) {
        self.nodes_visited += count;
    }

    /// Check if stop conditions are met.
    pub fn should_stop(&self) -> Option<StopReason> {
        // Check timeout
        if let Some(start) = self.start_time {
            let elapsed_ms = start.elapsed().as_millis() as u64;
            if elapsed_ms >= self.stop_conditions.timeout_ms {
                return Some(StopReason::Timeout(elapsed_ms));
            }
        }

        // Check RPC limit
        if self.rpc_calls >= self.stop_conditions.max_rpc_calls {
            return Some(StopReason::MaxRpcCalls(self.rpc_calls));
        }

        // Check node limit
        if self.nodes_visited >= self.stop_conditions.max_nodes_visited {
            return Some(StopReason::MaxNodes(self.nodes_visited));
        }

        None
    }

    /// Get elapsed time in milliseconds.
    pub fn elapsed_ms(&self) -> u64 {
        self.start_time
            .map(|s| s.elapsed().as_millis() as u64)
            .unwrap_or(0)
    }

    /// Get remaining timeout budget in milliseconds.
    pub fn remaining_ms(&self) -> u64 {
        let elapsed = self.elapsed_ms();
        self.stop_conditions.timeout_ms.saturating_sub(elapsed)
    }

    /// Mark a step as executed (remove from pending).
    pub fn mark_executed(&mut self, layer: &str) {
        if let Some(step) = self.steps.iter_mut().find(|s| s.layer == layer) {
            // Mark as "executed" by disabling - prevents re-execution
            step.enabled = false;
        }
    }
}

/// Reason execution was stopped.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum StopReason {
    /// Timeout exceeded
    Timeout(u64),
    /// Max RPC calls reached
    MaxRpcCalls(u32),
    /// Max nodes visited
    MaxNodes(u32),
    /// Max depth reached
    MaxDepth(u32),
    /// Token budget exhausted
    TokenBudget(u32),
    /// Sufficient results found (early stop)
    SufficientResults,
}

impl std::fmt::Display for StopReason {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            StopReason::Timeout(ms) => write!(f, "Timeout after {}ms", ms),
            StopReason::MaxRpcCalls(n) => write!(f, "Max RPC calls reached: {}", n),
            StopReason::MaxNodes(n) => write!(f, "Max nodes visited: {}", n),
            StopReason::MaxDepth(n) => write!(f, "Max depth reached: {}", n),
            StopReason::TokenBudget(n) => write!(f, "Token budget exhausted: {}", n),
            StopReason::SufficientResults => write!(f, "Sufficient results found"),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_layer_result_success() {
        let result = LayerResult::success("bm25", 10, 50, 0.8);
        assert!(result.success);
        assert!(result.is_sufficient());
        assert_eq!(result.result_count, 10);
    }

    #[test]
    fn test_layer_result_failure() {
        let result = LayerResult::failure("bm25", "Index not available", 10);
        assert!(!result.success);
        assert!(!result.is_sufficient());
    }

    #[test]
    fn test_fallback_step_can_execute() {
        let enabled = FallbackStep {
            layer: "bm25".to_string(),
            enabled: true,
            healthy: true,
            priority: 0,
        };
        assert!(enabled.can_execute());

        let disabled = FallbackStep {
            layer: "bm25".to_string(),
            enabled: false,
            healthy: true,
            priority: 0,
        };
        assert!(!disabled.can_execute());

        let unhealthy = FallbackStep {
            layer: "bm25".to_string(),
            enabled: true,
            healthy: false,
            priority: 0,
        };
        assert!(!unhealthy.can_execute());
    }

    #[test]
    fn test_fallback_chain_stop_conditions() {
        let conditions = StopConditions {
            max_rpc_calls: 5,
            max_nodes_visited: 10,
            timeout_ms: 100,
            ..Default::default()
        };

        let mut chain = FallbackChain::new(vec![], conditions);
        chain.start();

        // Should not stop initially
        assert!(chain.should_stop().is_none());

        // After max RPCs
        for _ in 0..5 {
            chain.record_rpc();
        }
        assert!(matches!(chain.should_stop(), Some(StopReason::MaxRpcCalls(_))));
    }

    #[test]
    fn test_fallback_chain_timeout() {
        let conditions = StopConditions {
            timeout_ms: 10,
            ..Default::default()
        };

        let mut chain = FallbackChain::new(vec![], conditions);
        chain.start();

        // Wait for timeout
        std::thread::sleep(std::time::Duration::from_millis(20));

        assert!(matches!(chain.should_stop(), Some(StopReason::Timeout(_))));
    }

    #[test]
    fn test_stop_reason_display() {
        assert_eq!(StopReason::Timeout(5000).to_string(), "Timeout after 5000ms");
        assert_eq!(StopReason::MaxRpcCalls(20).to_string(), "Max RPC calls reached: 20");
    }
}
```

Update `crates/memory-retrieval/src/lib.rs`:
```rust
pub mod fallback;
pub use fallback::{FallbackChain, FallbackStep, LayerResult, StopReason};
```
  </action>
  <verify>
```bash
cargo build -p memory-retrieval
cargo test -p memory-retrieval fallback
```
  </verify>
  <done>FallbackChain exists with stop condition enforcement; all tests pass</done>
</task>

<task type="auto">
  <name>Task 2: Create retrieval executor with parallel execution</name>
  <files>crates/memory-retrieval/src/executor.rs</files>
  <action>
Create `crates/memory-retrieval/src/executor.rs`:

```rust
//! Retrieval execution engine.
//!
//! Implements FR-15 through FR-18:
//! - FR-15: Mode selection (Sequential/Parallel/Hybrid)
//! - FR-16: Bounded fan-out (beam_width 2-5)
//! - FR-17: Early stopping on sufficient results
//! - FR-18: Rank merge across layers

use crate::fallback::{FallbackChain, LayerResult, StopReason};
use crate::tier::{CombinedStatus, RouteSelection, TierDetector};
use memory_types::retrieval::{ExecutionMode, QueryIntent, StopConditions};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::time::Instant;
use tracing::{debug, info, warn};

/// Standard RRF constant (from original RRF paper).
const RRF_K: f32 = 60.0;

/// Result from retrieval execution.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionResult {
    /// Query that was executed
    pub query: String,
    /// Detected/specified intent
    pub intent: QueryIntent,
    /// Execution mode used
    pub mode: ExecutionMode,
    /// Layer results in execution order
    pub layer_results: Vec<LayerResult>,
    /// Final merged results (doc_id -> score)
    pub merged_scores: HashMap<String, f32>,
    /// Total execution time in milliseconds
    pub total_duration_ms: u64,
    /// Whether execution completed or was stopped
    pub completed: bool,
    /// Stop reason if not completed
    pub stop_reason: Option<StopReason>,
    /// Explainability: why this path was taken
    pub explanation: String,
}

impl ExecutionResult {
    /// Get the best layer result (highest confidence with results).
    pub fn best_result(&self) -> Option<&LayerResult> {
        self.layer_results
            .iter()
            .filter(|r| r.success && r.result_count > 0)
            .max_by(|a, b| {
                a.confidence
                    .partial_cmp(&b.confidence)
                    .unwrap_or(std::cmp::Ordering::Equal)
            })
    }

    /// Check if any results were found.
    pub fn has_results(&self) -> bool {
        self.layer_results.iter().any(|r| r.result_count > 0)
    }

    /// Get total results across all layers.
    pub fn total_results(&self) -> usize {
        self.merged_scores.len()
    }
}

/// Retrieval executor that orchestrates layer execution.
///
/// Supports Sequential, Parallel, and Hybrid modes per PRD Section 5.4.
#[derive(Debug, Clone)]
pub struct RetrievalExecutor {
    /// Tier detector for capability assessment
    tier_detector: TierDetector,
    /// Default stop conditions
    default_conditions: StopConditions,
    /// Default execution mode
    default_mode: ExecutionMode,
}

impl RetrievalExecutor {
    /// Create a new executor with default settings.
    pub fn new() -> Self {
        Self {
            tier_detector: TierDetector::new(),
            default_conditions: StopConditions::default(),
            default_mode: ExecutionMode::Sequential,
        }
    }

    /// Configure default stop conditions.
    pub fn with_stop_conditions(mut self, conditions: StopConditions) -> Self {
        self.default_conditions = conditions;
        self
    }

    /// Configure default execution mode.
    pub fn with_mode(mut self, mode: ExecutionMode) -> Self {
        self.default_mode = mode;
        self
    }

    /// Execute retrieval with automatic layer selection and fallback.
    ///
    /// This is the main entry point implementing the decision algorithm
    /// from PRD Section 4.
    pub fn execute(
        &self,
        query: &str,
        intent: QueryIntent,
        status: &CombinedStatus,
        conditions: Option<StopConditions>,
    ) -> ExecutionResult {
        let start = Instant::now();
        let conditions = conditions.unwrap_or_else(|| self.conditions_for_intent(intent));

        // Step 1: Get route based on intent and tier
        let route = self.tier_detector.select_route(intent, status);
        debug!(
            query = %query,
            intent = ?intent,
            tier = ?status.tier,
            primary = route.primary,
            "Starting retrieval execution"
        );

        // Step 2: Create fallback chain
        let mut chain = FallbackChain::from_route(&route, status, conditions.clone());
        chain.start();

        // Step 3: Execute based on mode
        let mode = self.select_mode(intent, &conditions);
        let layer_results = match mode {
            ExecutionMode::Sequential => self.execute_sequential(&mut chain, query),
            ExecutionMode::Parallel => self.execute_parallel(&mut chain, query, &conditions),
            ExecutionMode::Hybrid => self.execute_hybrid(&mut chain, query, &conditions),
        };

        // Step 4: Merge results using RRF
        let merged_scores = self.merge_results(&layer_results);

        // Step 5: Build explanation
        let explanation = self.build_explanation(&route, &layer_results, status);

        let total_duration_ms = start.elapsed().as_millis() as u64;
        let stop_reason = chain.should_stop();

        info!(
            query = %query,
            duration_ms = total_duration_ms,
            results = merged_scores.len(),
            mode = ?mode,
            "Retrieval execution complete"
        );

        ExecutionResult {
            query: query.to_string(),
            intent,
            mode,
            layer_results,
            merged_scores,
            total_duration_ms,
            completed: stop_reason.is_none(),
            stop_reason,
            explanation,
        }
    }

    /// Get stop conditions adjusted for intent type.
    fn conditions_for_intent(&self, intent: QueryIntent) -> StopConditions {
        let mut conditions = self.default_conditions.clone();

        match intent {
            QueryIntent::TimeBoxed => {
                // Stricter limits for time-boxed
                conditions.timeout_ms = conditions.timeout_ms.min(2000);
                conditions.max_rpc_calls = conditions.max_rpc_calls.min(10);
                conditions.max_nodes_visited = conditions.max_nodes_visited.min(50);
            }
            QueryIntent::Locate => {
                // Allow more depth for locate (finding exact match)
                conditions.max_depth = conditions.max_depth.max(7);
            }
            QueryIntent::Explore => {
                // Allow more breadth for explore
                conditions.max_nodes_visited = conditions.max_nodes_visited.max(150);
            }
            QueryIntent::Answer => {
                // Default conditions are fine
            }
        }

        conditions
    }

    /// Select execution mode based on intent and conditions.
    fn select_mode(&self, intent: QueryIntent, conditions: &StopConditions) -> ExecutionMode {
        // TimeBoxed always uses parallel if beam_width > 1
        if intent == QueryIntent::TimeBoxed && conditions.beam_width > 1 {
            return ExecutionMode::Parallel;
        }

        // Use configured default, respecting beam_width
        if conditions.beam_width > 1 {
            self.default_mode
        } else {
            ExecutionMode::Sequential
        }
    }

    /// Execute layers sequentially (FR-15 sequential mode).
    fn execute_sequential(&self, chain: &mut FallbackChain, query: &str) -> Vec<LayerResult> {
        let mut results = Vec::new();

        while let Some(step) = chain.next_step() {
            // Check stop conditions before each step
            if let Some(reason) = chain.should_stop() {
                debug!(layer = %step.layer, reason = %reason, "Stopping due to stop condition");
                break;
            }

            // Simulate layer execution (actual impl would call real RPCs)
            let layer_name = step.layer.clone();
            let result = self.execute_layer(&layer_name, query, chain);

            // Mark step as executed
            chain.mark_executed(&layer_name);
            chain.record_rpc();

            // Check if results are sufficient
            let is_fallback = !results.is_empty();
            let mut result = if is_fallback {
                result.as_fallback()
            } else {
                result
            };

            results.push(result.clone());

            // Early stop if sufficient results
            if result.is_sufficient() {
                debug!(layer = %layer_name, "Sufficient results found, stopping");
                break;
            }
        }

        results
    }

    /// Execute layers in parallel (FR-15 parallel mode, FR-16 bounded fan-out).
    fn execute_parallel(
        &self,
        chain: &mut FallbackChain,
        query: &str,
        conditions: &StopConditions,
    ) -> Vec<LayerResult> {
        let executable = chain.executable_steps();
        let beam_width = (conditions.beam_width as usize).min(5).max(1);

        // Take up to beam_width steps
        let parallel_steps: Vec<_> = executable.into_iter().take(beam_width).collect();

        debug!(
            beam_width = beam_width,
            layers = ?parallel_steps.iter().map(|s| &s.layer).collect::<Vec<_>>(),
            "Executing parallel"
        );

        // Execute all in parallel (simulated - actual impl would use tokio::spawn)
        let mut results: Vec<LayerResult> = parallel_steps
            .iter()
            .map(|step| {
                chain.record_rpc();
                self.execute_layer(&step.layer, query, chain)
            })
            .collect();

        // Sort by confidence descending
        results.sort_by(|a, b| {
            b.confidence
                .partial_cmp(&a.confidence)
                .unwrap_or(std::cmp::Ordering::Equal)
        });

        results
    }

    /// Execute with hybrid mode (FR-15 hybrid mode).
    ///
    /// Starts parallel, cancels losers when one dominates.
    fn execute_hybrid(
        &self,
        chain: &mut FallbackChain,
        query: &str,
        conditions: &StopConditions,
    ) -> Vec<LayerResult> {
        // Start with parallel
        let results = self.execute_parallel(chain, query, conditions);

        // If best result has strong confidence, we're done
        if let Some(best) = results.first() {
            if best.confidence > 0.8 {
                debug!(
                    layer = %best.layer,
                    confidence = best.confidence,
                    "Strong result found, canceling others"
                );
                return vec![best.clone()];
            }
        }

        // Otherwise return all results for fusion
        results
    }

    /// Execute a single layer (placeholder - actual impl calls real RPCs).
    fn execute_layer(&self, layer: &str, _query: &str, _chain: &FallbackChain) -> LayerResult {
        // This is a placeholder - actual implementation would:
        // - For "bm25": call TeleportSearch RPC
        // - For "vector": call VectorTeleport RPC
        // - For "hybrid": call HybridSearch RPC
        // - For "topics": call GetTopicsByQuery RPC
        // - For "agentic": call SearchChildren RPC

        // Simulate based on layer type
        match layer {
            "agentic" => {
                // Agentic always works
                LayerResult::success(layer, 5, 100, 0.5)
            }
            _ => {
                // Simulate success for other layers
                LayerResult::success(layer, 10, 50, 0.75)
            }
        }
    }

    /// Merge results from multiple layers using Reciprocal Rank Fusion (FR-18).
    fn merge_results(&self, layer_results: &[LayerResult]) -> HashMap<String, f32> {
        let mut scores: HashMap<String, f32> = HashMap::new();

        // For now, just combine based on layer confidence
        // Actual impl would merge actual doc_ids from results
        for (layer_rank, result) in layer_results.iter().enumerate() {
            if result.success && result.result_count > 0 {
                // RRF score contribution
                let rrf_score = result.confidence / (RRF_K + layer_rank as f32 + 1.0);

                // Create synthetic doc_id for demonstration
                let doc_key = format!("{}_{}", result.layer, layer_rank);
                *scores.entry(doc_key).or_default() += rrf_score;
            }
        }

        scores
    }

    /// Build explanation of retrieval path (FR-19).
    fn build_explanation(
        &self,
        route: &RouteSelection,
        results: &[LayerResult],
        status: &CombinedStatus,
    ) -> String {
        let mut parts = Vec::new();

        parts.push(format!(
            "Tier: {} ({})",
            status.tier as u8, status.description
        ));
        parts.push(format!("Route: {}", route.explanation));

        for result in results {
            let status = if result.success {
                if result.is_fallback {
                    "fallback"
                } else {
                    "primary"
                }
            } else {
                "failed"
            };
            parts.push(format!(
                "- {}: {} ({} results, {:.2} confidence, {}ms)",
                result.layer, status, result.result_count, result.confidence, result.duration_ms
            ));
        }

        parts.join("\n")
    }
}

impl Default for RetrievalExecutor {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::tier::TierDetector;
    use memory_types::retrieval::LayerStatus;

    fn ready_status() -> LayerStatus {
        LayerStatus {
            enabled: true,
            healthy: true,
            doc_count: 100,
        }
    }

    fn disabled_status() -> LayerStatus {
        LayerStatus {
            enabled: false,
            healthy: false,
            doc_count: 0,
        }
    }

    #[test]
    fn test_executor_sequential() {
        let executor = RetrievalExecutor::new();
        let detector = TierDetector::new();

        let status = detector.detect(ready_status(), ready_status(), disabled_status());

        let result = executor.execute("test query", QueryIntent::Answer, &status, None);

        assert!(result.has_results());
        assert_eq!(result.mode, ExecutionMode::Sequential);
        assert!(!result.layer_results.is_empty());
    }

    #[test]
    fn test_executor_with_custom_conditions() {
        let conditions = StopConditions {
            timeout_ms: 1000,
            max_rpc_calls: 5,
            ..Default::default()
        };

        let executor = RetrievalExecutor::new().with_stop_conditions(conditions);
        let detector = TierDetector::new();
        let status = detector.detect(ready_status(), ready_status(), disabled_status());

        let result = executor.execute("test", QueryIntent::Answer, &status, None);
        assert!(result.total_duration_ms < 1000);
    }

    #[test]
    fn test_executor_time_boxed_stricter_limits() {
        let executor = RetrievalExecutor::new();
        let detector = TierDetector::new();
        let status = detector.detect(ready_status(), ready_status(), disabled_status());

        let result = executor.execute("test", QueryIntent::TimeBoxed, &status, None);

        // TimeBoxed should complete quickly
        assert!(result.total_duration_ms < 2000);
    }

    #[test]
    fn test_executor_agentic_fallback() {
        let executor = RetrievalExecutor::new();
        let detector = TierDetector::new();

        // All layers disabled = Tier 5 (agentic only)
        let status = detector.detect(disabled_status(), disabled_status(), disabled_status());

        let result = executor.execute("test", QueryIntent::Answer, &status, None);

        // Should still have results from agentic
        assert!(result.has_results());
        assert!(result
            .layer_results
            .iter()
            .any(|r| r.layer == "agentic" && r.success));
    }

    #[test]
    fn test_execution_result_best_result() {
        let result = ExecutionResult {
            query: "test".to_string(),
            intent: QueryIntent::Answer,
            mode: ExecutionMode::Sequential,
            layer_results: vec![
                LayerResult::success("bm25", 10, 50, 0.7),
                LayerResult::success("agentic", 5, 100, 0.5),
            ],
            merged_scores: HashMap::new(),
            total_duration_ms: 150,
            completed: true,
            stop_reason: None,
            explanation: String::new(),
        };

        let best = result.best_result().unwrap();
        assert_eq!(best.layer, "bm25");
        assert_eq!(best.confidence, 0.7);
    }

    #[test]
    fn test_merge_results_rrf() {
        let executor = RetrievalExecutor::new();
        let results = vec![
            LayerResult::success("bm25", 10, 50, 0.8),
            LayerResult::success("vector", 8, 60, 0.7),
        ];

        let merged = executor.merge_results(&results);
        assert!(!merged.is_empty());
    }
}
```

Update `crates/memory-retrieval/src/lib.rs`:
```rust
pub mod executor;
pub use executor::{RetrievalExecutor, ExecutionResult};
```
  </action>
  <verify>
```bash
cargo build -p memory-retrieval
cargo test -p memory-retrieval executor
```
  </verify>
  <done>RetrievalExecutor exists with sequential/parallel/hybrid modes; all tests pass</done>
</task>

</tasks>

<verification>
After all tasks complete:

```bash
# Full workspace build
cargo build --workspace

# All memory-retrieval tests
cargo test -p memory-retrieval --all-features

# Clippy check
cargo clippy -p memory-retrieval -- -D warnings

# Doc tests
cargo test -p memory-retrieval --doc
```
</verification>

<success_criteria>
1. FallbackChain executes layers in order with stop condition enforcement
2. RetrievalExecutor supports Sequential, Parallel, and Hybrid modes
3. Stop conditions (timeout, max_nodes, max_rpc_calls) are respected
4. Parallel execution respects beam_width (bounded fan-out)
5. Agentic fallback always available (never hard-fail)
6. RRF merge combines results from multiple layers
7. Execution produces explainability explanation
8. All unit tests pass
9. Clippy passes with no warnings
</success_criteria>

<output>
After completion, create `.planning/phases/17-agent-retrieval-policy/17-04-SUMMARY.md`
</output>
