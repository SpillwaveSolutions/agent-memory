---
phase: 13-outbox-index-ingestion
plan: 02
type: execute
wave: 2
depends_on: ["13-01"]
files_modified:
  - crates/memory-indexing/Cargo.toml
  - crates/memory-indexing/src/lib.rs
  - crates/memory-indexing/src/pipeline.rs
  - crates/memory-indexing/src/consumer.rs
autonomous: true

must_haves:
  truths:
    - "IndexingPipeline processes outbox entries in batches"
    - "Each entry triggers appropriate index update based on action type"
    - "Checkpoint is saved after successful batch processing"
    - "Index operations are idempotent (delete-then-add pattern)"
  artifacts:
    - path: "crates/memory-indexing/src/pipeline.rs"
      provides: "Main indexing pipeline orchestration"
      contains: "IndexingPipeline"
      min_lines: 100
    - path: "crates/memory-indexing/src/consumer.rs"
      provides: "Outbox entry dispatch logic"
      contains: "process_batch"
  key_links:
    - from: "crates/memory-indexing/src/pipeline.rs"
      to: "crates/memory-storage/src/db.rs"
      via: "Storage for checkpoint and outbox"
      pattern: "storage\\.get_outbox_entries"
    - from: "crates/memory-indexing/src/pipeline.rs"
      to: "checkpoint.rs"
      via: "IndexCheckpoint for progress tracking"
      pattern: "IndexCheckpoint"
---

<objective>
Implement the IndexingPipeline for processing outbox entries and dispatching to indexers.

Purpose: Create the core orchestration that reads outbox entries, dispatches to BM25/vector indexers, and tracks progress.
Output: IndexingPipeline with process_batch() method that handles incremental index updates.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-outbox-index-ingestion/13-RESEARCH.md
@.planning/phases/13-outbox-index-ingestion/13-01-SUMMARY.md
@crates/memory-indexing/src/lib.rs
@crates/memory-indexing/src/checkpoint.rs
@crates/memory-storage/src/db.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create indexer trait definitions</name>
  <files>crates/memory-indexing/src/pipeline.rs</files>
  <action>
    Create pipeline.rs with trait definitions for pluggable indexers:

    1. Define Bm25Indexer trait (Send + Sync):
       - async fn index_toc_node(&self, node: &TocNode) -> Result<(), IndexingError>
       - async fn index_grip(&self, grip: &Grip) -> Result<(), IndexingError>
       - async fn delete_document(&self, doc_id: &str) -> Result<(), IndexingError>
       - async fn commit(&self) -> Result<(), IndexingError>

    2. Define VectorIndexer trait (Send + Sync):
       - async fn index_toc_node(&self, node: &TocNode) -> Result<(), IndexingError>
       - async fn index_grip(&self, grip: &Grip) -> Result<(), IndexingError>
       - async fn delete_document(&self, doc_id: &str) -> Result<(), IndexingError>
       - async fn commit(&self) -> Result<(), IndexingError>

    3. Create IndexingStats struct:
       - bm25_indexed: u64
       - vector_indexed: u64
       - toc_updates: u64
       - skipped: u64
       - errors: u64
       - Implement total() -> u64 method

    4. Create IndexingPipelineConfig struct:
       - batch_size: usize (default 100)
       - enable_bm25: bool (default true)
       - enable_vector: bool (default true)
       - checkpoint_name: String (default "index_combined")
       - Implement Default trait

    These traits will be implemented by memory-search (Bm25Indexer) and memory-vector (VectorIndexer) in later phases.
    For now, the pipeline uses Option<Arc<dyn Trait>> to allow either or both to be None.
  </action>
  <verify>cargo check -p memory-indexing compiles</verify>
  <done>Bm25Indexer and VectorIndexer traits defined with IndexingStats and config</done>
</task>

<task type="auto">
  <name>Task 2: Implement IndexingPipeline struct</name>
  <files>crates/memory-indexing/src/pipeline.rs, crates/memory-indexing/src/consumer.rs</files>
  <action>
    Create IndexingPipeline struct in pipeline.rs:

    ```rust
    pub struct IndexingPipeline {
        storage: Arc<Storage>,
        bm25_indexer: Option<Arc<dyn Bm25Indexer>>,
        vector_indexer: Option<Arc<dyn VectorIndexer>>,
        config: IndexingPipelineConfig,
    }
    ```

    Implement:
    1. new() constructor taking storage, optional indexers, and config
    2. load_checkpoint() -> Result<Option<IndexCheckpoint>, IndexingError>
       - Use storage.get_checkpoint() with config.checkpoint_name
       - Deserialize with IndexCheckpoint::from_bytes()
    3. save_checkpoint(last_sequence: u64, stats: &IndexingStats) -> Result<(), IndexingError>
       - Create new IndexCheckpoint with current time
       - Serialize and save via storage.put_checkpoint()

    Create consumer.rs with process_batch() implementation:
    1. Load checkpoint to get starting sequence (or start at 0)
    2. Call storage.get_outbox_entries(start_seq, batch_size)
    3. For each entry, dispatch based on entry.action:
       - OutboxAction::IndexEvent: Index for both BM25 and vector if enabled
       - OutboxAction::UpdateToc: Re-index the TOC node
    4. After processing batch, save checkpoint
    5. Return IndexingStats

    Handle idempotent updates:
    - Use delete_document() before indexing to handle re-indexing
    - Log warnings for errors but continue processing (don't fail entire batch)

    Add tracing for observability (info! for batch completion, warn! for errors).
  </action>
  <verify>cargo check -p memory-indexing compiles</verify>
  <done>IndexingPipeline struct exists with checkpoint load/save and process_batch</done>
</task>

<task type="auto">
  <name>Task 3: Add unit tests with mock indexers</name>
  <files>crates/memory-indexing/src/pipeline.rs</files>
  <action>
    Create comprehensive tests in pipeline.rs #[cfg(test)] module:

    1. Create MockBm25Indexer that:
       - Tracks indexed items in Arc<Mutex<Vec<String>>>
       - Implements all Bm25Indexer trait methods
       - Returns Ok(()) for all operations

    2. Create MockVectorIndexer similarly

    3. Write tests:
       - test_empty_outbox_returns_zero_stats: Empty outbox returns stats with all zeros
       - test_process_batch_indexes_entries: Add outbox entries, verify mock indexers receive them
       - test_checkpoint_persists_progress: Process batch, verify checkpoint saved
       - test_checkpoint_resume_from_last: Process partial, verify next batch starts from checkpoint
       - test_skips_when_no_indexers: Both indexers None, entries still processed (checkpoint advanced)
       - test_error_handling_continues: One indexer fails, other continues

    Use tempfile for Storage instances in tests.
    Add helper function to create test outbox entries.
  </action>
  <verify>cargo test -p memory-indexing -- pipeline passes</verify>
  <done>Unit tests pass for IndexingPipeline with mock indexers</done>
</task>

</tasks>

<verification>
1. `cargo build -p memory-indexing` compiles without warnings
2. `cargo test -p memory-indexing` all tests pass
3. `cargo clippy -p memory-indexing -- -D warnings` no lint errors
4. IndexingPipeline correctly dispatches to both indexer types
</verification>

<success_criteria>
- Bm25Indexer and VectorIndexer traits defined for pluggable indexers
- IndexingPipeline processes outbox entries in configurable batches
- Checkpoint is saved after each batch with last sequence number
- process_batch() returns accurate IndexingStats
- Mock indexer tests verify correct dispatch behavior
</success_criteria>

<output>
After completion, create `.planning/phases/13-outbox-index-ingestion/13-02-SUMMARY.md`
</output>
